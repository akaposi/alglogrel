\documentclass[dvipsnames]{lmcs} %%% last changed 2014-08-20

%% build: latexmk -pdf -pvc -interaction=nonstopmode paper.tex

%% mandatory lists of keywords
\keywords{homotopy type theory, higher inductive types, inductive types}

%% read in additional TeX-packages or personal macros here:
%% e.g. \usepackage{tikz}
%% \usepackage[dvipsnames]{xcolor}
\usepackage{microtype}
\usepackage{proof}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\bibliographystyle{plainurl}
\usepackage{hyperref}

%% ABBREVS
%% --------------------------------------------------------------------------------

%% setting \sqcdot as HoTT-book-style transitivity
\makeatletter
\DeclareRobustCommand{\sqcdot}{\mathbin{\mathpalette\morphic@sqcdot\relax}}
\newcommand{\morphic@sqcdot}[2]{%
  \sbox\z@{$\m@th#1\centerdot$}%
  \ht\z@=.33333\ht\z@
  \vcenter{\box\z@}%
}
\makeatother

\newcommand{\U}{\mathsf{U}}
\newcommand{\El}{\mathsf{El}}
\newcommand{\REN}{\mathsf{REN}}
\newcommand{\op}{\mathsf{op}}
\newcommand{\ra}{\rightarrow}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\Set}{\mathsf{Set}}
\newcommand{\PSh}{\mathsf{PSh}}
\newcommand{\FamPSh}{\mathsf{FamPSh}}
\renewcommand{\ll}{\llbracket}
\providecommand{\rr}{\rrbracket}
\newcommand{\Con}{\mathsf{Con}}
\newcommand{\Ty}{\mathsf{Ty}}
\newcommand{\Tm}{\mathsf{Tm}}
\newcommand{\Sub}{\mathsf{Sub}}
\newcommand{\R}{\mathsf{R}}
\newcommand{\TM}{\mathsf{TM}}
\newcommand{\NE}{\mathsf{NE}}
\newcommand{\NF}{\mathsf{NF}}
\newcommand{\p}{\mathsf{p}}
\newcommand{\q}{\mathsf{q}}
\renewcommand{\u}{\mathsf{u}}
\renewcommand{\ne}{\mathsf{ne}}
\newcommand{\nf}{\mathsf{nf}}
\newcommand{\lQ}{\mathsf{lQ}}
\newcommand{\lU}{\mathsf{lU}}
\renewcommand{\lq}{\mathsf{lq}}
\newcommand{\lu}{\mathsf{lu}}
\newcommand{\cul}{\ulcorner}
\newcommand{\cur}{\urcorner}
\newcommand{\norm}{\mathsf{norm}}
\newcommand{\Nf}{\mathsf{Nf}}
\newcommand{\Ne}{\mathsf{Ne}}
\newcommand{\Nfs}{\mathsf{Nfs}}
\newcommand{\Nes}{\mathsf{Nes}}
\newcommand{\ID}{\mathsf{ID}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\nat}{\,\dot{\rightarrow}\,}
\newcommand{\Nat}{\mathsf{Nat}}
%% \renewcommand{\S}{\overset{\mathsf{s}}{\ra}}
\newcommand{\blank}{\mathord{\hspace{1pt}\text{--}\hspace{1pt}}}
\newcommand{\lam}{\mathsf{lam}}
\newcommand{\app}{\mathsf{app}}
\newcommand{\tr}[2]{\ensuremath{{}_{#1 *}\mathopen{}{#2}\mathclose{}}}
\newcommand{\C}{\mathsf{C}}
\newcommand{\Code}{\mathsf{Code}}

\newcommand{\A}{\mathsf{A}}
\newcommand{\M}{\mathsf{M}}
\newcommand{\D}{\mathsf{D}}
\renewcommand{\S}{\mathsf{S}}

\newcommand{\data}{\mathsf{data}}
\newcommand{\ind}{\hspace{1em}}
\newcommand{\idP}{\mathsf{idP}}
\newcommand{\compP}{\mathsf{compP}}
\newcommand{\idF}{\mathsf{idF}}
\newcommand{\compF}{\mathsf{compF}}
\newcommand{\proj}{\mathsf{proj}}
\newcommand{\ExpPSh}{\mathsf{ExpPSh}}
\newcommand{\map}{\mathsf{map}}
\newcommand{\Var}{\mathsf{Var}}
\newcommand{\Vars}{\mathsf{Vars}}
\newcommand{\wk}{\mathsf{wk}}
\newcommand{\neuU}{\mathsf{neuU}}
\newcommand{\neuEl}{\mathsf{neuEl}}
\newcommand{\var}{\mathsf{var}}
\newcommand{\natn}{\mathsf{natn}}
\newcommand{\natS}{\mathsf{natS}}
\newcommand{\LET}{\mathsf{let}}
\newcommand{\IN}{\mathsf{in}}
\newcommand{\refl}{\mathsf{refl}}
\newcommand{\trans}{\mathbin{\raisebox{0.2ex}{$\displaystyle\centerdot$}}}
\newcommand{\zero}{\mathsf{zero}}
\newcommand{\suc}{\mathsf{suc}}
\newcommand{\N}{\mathbb{N}}

\newcommand\arcfrombottom{
  \begin{tikzpicture}[scale=0.03em]
    \draw (0,0) arc (0:180:0.5);
    \draw (0,0) edge[->] (0,-0.3);
    \draw (-1,0) edge (-1,-0.3);
  \end{tikzpicture}
}
\newcommand\arcfromtop{
  \begin{tikzpicture}[scale=0.03em]
    \draw (0,0) arc (180:360:0.5);
    \draw (0,0) edge[->] (0,0.3);
    \draw (1,0) edge (1,0.3);
  \end{tikzpicture}
}

\newcommand{\Elim}{\mathsf{Elim}}
\newcommand{\elim}{\mathsf{elim}}
\newcommand{\Rec}{\mathsf{Rec}}
\newcommand{\record}{\mathsf{record}}
\newcommand{\funext}{\mathsf{funext}} \newcommand{\Q}{\mathsf{Q}}
\newcommand{\T}{\mathsf{T}} \newcommand{\leaf}{\mathsf{leaf}}
\newcommand{\node}{\mathsf{node}} \newcommand{\perm}{\mathsf{perm}}
\newcommand{\coe}{\mathsf{coe}} \newcommand{\vz}{\mathsf{vz}}
\newcommand{\vs}{\mathsf{vs}} \newcommand{\untr}{\mathsf{untr}}
\newcommand{\from}{\mathsf{from}}
\newcommand{\fromeq}{{\mathsf{from}\hspace{-0.3em}\equiv}}
\newcommand{\fromsimeq}{{\mathsf{from}\hspace{-0.3em}\simeq}}
\newcommand{\Model}{\mathsf{Model}}
\newcommand{\DModel}{\mathsf{DModel}}
\newcommand{\module}{\mathsf{module}}
\newcommand{\open}{\mathsf{open}}
\renewcommand{\P}{\mathsf{P}} \newcommand{\Bool}{\mathsf{Bool}}
\newcommand{\true}{\mathsf{true}} \newcommand{\false}{\mathsf{false}}
\renewcommand{\not}{\mathsf{not}} \newcommand{\0}{\mathsf{0}}
\newcommand{\1}{\mathsf{1}} \renewcommand{\Pr}{\mathsf{Pr}}
\newcommand{\PrNat}{\mathsf{PrNat}} \newcommand{\J}{\mathsf{J}}
\newcommand{\wkV}{\mathsf{wkV}} \renewcommand{\r}[1]{{\P_{#1}}}
\newcommand{\stab}{\mathsf{stab}} \newcommand{\NTy}{\mathsf{NTy}}
\newcommand{\isDec}{\mathsf{isDec}} \newcommand{\dec}{\mathsf{dec}}
\newcommand{\yes}{\mathsf{yes}} \newcommand{\no}{\mathsf{no}}
\newcommand{\case}{\mathsf{case}} \newcommand{\inj}{\mathsf{inj}}
\newcommand{\K}{\mathsf{K}} \newcommand{\lb}{\langle}
\newcommand{\rb}{\rangle} \newcommand{\Decl}{\mathsf{Decl}}
\newcommand{\Core}{\mathsf{Core}} \newcommand{\IND}{\mathsf{ind}}
\newcommand{\Id}{\mathsf{Id}} \newcommand{\Base}{\mathsf{Base}}
\newcommand{\transport}{\mathsf{transport}}
\newcommand{\I}{\mathsf{I}} \newcommand{\E}{\mathsf{S}}
\newcommand{\transp}{\mathsf{transp}}
\newcommand{\Transp}{\mathsf{Transp}}
\newcommand{\W}{\mathsf{W}}
\newcommand{\Fin}{\mathsf{Fin}} \newcommand{\fzero}{\mathsf{fzero}}
\newcommand{\fsuc}{\mathsf{fsuc}}
\newcommand{\inv}{\mathsf{inv}}
\newcommand{\con}{\mathsf{con}}
\newcommand{\LEFT}{\mathsf{left}}
\newcommand{\RIGHT}{\mathsf{right}}
\newcommand{\seg}{\mathsf{seg}}
\newcommand{\Int}{\mathsf{Int}}
\renewcommand{\in}{\mathbin{\hat:}}
\renewcommand{\hat}[1]{{\color{BrickRed}{#1}}}
\newcommand{\blc}[1]{{\color{Black}{#1}}}
\newcommand{\vdashh}{\mathbin{\hat\vdash}}
\newcommand{\rah}{\mathbin{\hat\ra}}
\newcommand{\commah}{\hat,\,}
\newcommand{\timesh}{\mathbin{\hat\times}}
\newcommand{\eqh}{\mathbin{\hat=}}
\newcommand{\TR}{\hat{\mathsf{tr}}}
\newcommand{\ap}{\hat{\mathsf{ap}}}
\newcommand{\apd}{\hat{\mathsf{apd}}}
\renewcommand{\tt}{\hat{\mathsf{tt}}}
\newcommand{\Tel}{\hat{\mathsf{Tel}}}
\newcommand{\Type}{\hat{\mathsf{Type}}}
\newcommand{\emptytel}{\hat{\epsilon}}
\newcommand{\telext}{\mathbin{\hat{\lhd}}}
\newcommand{\ltel}{\hat{\ll}}
\newcommand{\rtel}{\hat{\rr}}
\newcommand\pp{\ensuremath{\hat{\mathbin{+\mkern-10mu+}}}}
\newcommand{\semicol}{\hat;\,}
\newcommand{\targetass}{\hat{\Gamma}\semicol}
\newcommand{\Alg}{\mathsf{Alg}}
\newcommand{\DisplayedAlg}{\mathsf{DisplayedAlg}}
\newcommand{\Morphism}{\mathsf{Morphism}}
\newcommand{\Section}{\mathsf{Section}}
\newcommand{\ass}{\mathsf{ass}}
\newcommand{\idl}{\mathsf{idl}}
\newcommand{\idr}{\mathsf{idr}}
\newcommand{\inv}{\mathsf{inv}}


%% END OF ABBREVS
%% --------------------------------------------------------------------------------

%%\input{myMacros.tex}
%% define non-standard environments BEYOND the ones already supplied
%% here, for example
\theoremstyle{plain}\newtheorem{satz}[thm]{Satz} %\crefname{satz}{Satz}{S\"atze}
%% Do NOT replace the proclamation environments lready provided by
%% your own.

\def\eg{{\em e.g.}}
\def\cf{{\em cf.}}

%% due to the dependence on amsart.cls, \begin{document} has to occur
%% BEFORE the title and author information:

\begin{document}

\title{Signatures and Induction Principles for Higher Inductive-Inductive Types}
\titlecomment{{\lsuper*} This is a journal version of the paper \cite{hiit}.}

\author[A.~Kaposi]{Ambrus Kaposi}	%required
\address{Department of Programming Languages and Compilers, E{\"o}tv{\"o}s Lor{\'a}nd University, Budapest, Hungary}	%required
\email{akaposi@inf.elte.hu}  %optional
%\thanks{thanks 1, optional.}	%optional

\author[A.~Kov{\'a}cs]{Andr{\'a}s Kov{\'a}cs}	%optional
\address{Department of Programming Languages and Compilers, E{\"o}tv{\"o}s Lor{\'a}nd University, Budapest, Hungary}	%required
\email{kovacsandras@inf.elte.hu}  %optional
\thanks{This work was supported by the European Union, co-financed by the
European Social Fund (EFOP-3.6.3-VEKOP-16-2017-00002) and COST Action
EUTypes CA15123.}	%optional

%% required for running head on odd and even pages, use suitable
%% abbreviations in case of long titles and many authors:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% the abstract has to PRECEDE the command \maketitle:
%% be sure not to issue the \maketitle command twice!

\begin{abstract}
\noindent
Higher inductive-inductive types (HIITs) generalize inductive types of dependent
type theories in two ways. On the one hand they allow the simultaneous
definition of multiple sorts that can be indexed over each other. On the other
hand they support equality constructors, thus generalizing higher inductive
types of homotopy type theory. Examples that make use of both features are the
Cauchy reals and the well-typed syntax of type theory where conversion rules are
given as equality constructors. In this paper we propose a general definition of
HIITs using a small type theory, named the theory of signatures. A context in
this theory encodes a HIIT by listing the constructors. We also compute notions
of induction and recursion for HIITs, by using variants of syntactic logical
relation translations. Building full categorical semantics and constructing
initial algebras is left for future work. The theory of HIIT signatures was
formalised in Agda together with the syntactic translations. We also provide a
Haskell implementation, which takes signatures as input and outputs translation
results as valid Agda code.
\end{abstract}

\maketitle


\section{Introduction}
\label{sec:intro}

Many dependent type theories support some form of inductive types. An
inductive type is given by its constructors, along with an elimination
principle which expresses that all inhabitants are constructed using
finitely many applications of the constructors.

For example, the inductive type of natural numbers $\Nat$ is given by
the constructors $\zero:\Nat$ and $\suc:\Nat \ra \Nat$, and has the
well-known induction principle:
\[
  \Elim\Nat:(P:\Nat \ra \mathsf{Type})(pz: P\,\zero)\big(ps:(n:\Nat)\ra P\,n\ra P\,(\suc\,n)\big)(n:\Nat)\ra P\,n
\]
\noindent $P$ is a family of types (or: a proof-relevant predicate) over natural
numbers, which is called the \emph{induction motive}. The arguments $pz$ and
$ps$ are called the \emph{induction methods}. The behavior of induction is
described by a \emph{computation rule} ($\beta$-rule) for each constructor
and induction method:
\begin{alignat*}{5}
  & \Elim\Nat\,P\,pz\,ps\,\zero && \equiv pz \\
  & \Elim\Nat\,P\,pz\,ps\,(\suc\,n) && \equiv ps\,n\,(\Elim\Nat\,P\,pz\,ps\,n)
\end{alignat*}

%% These express that the eliminator applied to a constructor expression
%% reduces to an application of the corresponding induction method. From
%% an operational point of view, $\Elim\Nat$ replaces all the $\zero$ and
%% $\suc$ constructors with the given induction methods.

% A special case of the eliminator is the recursor (non-dependent
% eliminator) which allows the definition of a non-dependent function
% from the inductive type, for $\Nat$ it has the following type.
% \[
% \Rec\Nat : \forall(A:\mathsf{Type}).A \ra (A \ra A) \ra \Nat \ra A
% \]
% The eliminator can be derived from the recursor and a uniqueness
% principle.

Indexed families of types can be also considered, for example length-indexed
vectors of $A$-elements $\mathsf{Vec}_A: \Nat \ra \mathsf{Type}$. Mutual
inductive types are yet another generalization, however, they can be reduced to
indexed families where indices classify constructors for each mutual type.
Inductive-inductive types \cite{forsberg-phd} are mutual definitions where this
reduction does not work: here a type can be defined together with a family
indexed over it. An example is the following fragment of a well-typed syntax of
a type theory, where the second $\Ty$ type constructor is indexed over $\Con$,
but constructors of $\Con$ also refer to $\Ty$:
\begin{alignat*}{3}
  & \Con && : \mathsf{Type} && \text{contexts} \\
  & \Ty  && : \Con \ra \mathsf{Type} && \text{types in contexts} \\
  & \bullet && : \Con && \text{constructor for the empty context} \\
  & \blank\rhd\blank && : (\Gamma:\Con)\ra\Ty\,\Gamma\ra\Con && \text{constructor for context extension} \\
  & \iota && : (\Gamma:\Con)\ra\Ty\,\Gamma && \text{constructor for a base type} \\
  & \Pi && : (\Gamma:\Con)(A:\Ty\,\Gamma)\ra\Ty\,(\Gamma\rhd A)\ra\Ty\,\Gamma \hspace{1em} && \text{constructor for dependent functions}
\end{alignat*}
There are two eliminators for this type: one for $\Con$ and one for
$\Ty$. Both take the same arguments: two motives ($P:\Con\ra\mathsf{Type}$ and
$Q:(\Gamma:\Con)\ra P\,\Gamma\ra\Ty\,\Gamma\ra\mathsf{Type}$) and four methods
(one for each constructor, which we omit).
\begin{alignat*}{6}
  & \Elim\Con && : (P:\dots)(Q:\dots)\ra\dots\ra(\Gamma:\Con) && \ra P\,\Gamma \\
  & \Elim\Ty  && : (P:\dots)(Q:\dots)\ra\dots\ra(A:\Ty\,\Gamma) && \ra Q\,\Gamma\,(\Elim\Con\,\Gamma)\,A
\end{alignat*}
Note that the type of $\Elim\Ty$ refers to $\Elim\Con$; for this reason
this elimination principle is sometimes called ``recursive-recursive''
(analogously to ``inductive-inductive'').

Higher inductive types (HITs, \cite[Chapter 6]{HoTTbook}) generalize inductive
types in a different way: they allow constructors expressing equalities of
elements of the type being defined. This enables, among others, the definition
of types quotiented by a relation. For example, the type of integers $\Int$ can
be given by a constructor $\mathsf{pair}:\Nat\ra\Nat\ra\Int$ and an equality
constructor $\mathsf{eq}:(a\,b\,c\,d:\Nat)\ra a+d=_\Nat b+c\ra
\mathsf{pair}\,a\,b=_{\Int}\mathsf{pair}\,c\,d$ targetting an equality of
$\Int$. The eliminator for $\Int$ expects a motive $P:\Int\ra\mathsf{Type}$, a
method for the $\mathsf{pair}$ constructor $p:(a\,b:\Nat)\ra
P\,(\mathsf{pair}\,a\,b)$ and a method for the equality constructor
$\mathsf{path}$. This method is a proof that given $e:a+d=_\Nat b+c$, $p\,a\,b$
is equal to $p\,c\,d$ (the types of which are equal by $e$). Thus the method for
the equality constructor ensures that all functions defined from the quotiented
type respect the relation. Since the integers are supposed to be a set (which
means that any two equalities between the same two integers are equal), we would
need an additional higher equality constructor
$\mathsf{trunc}:(x\,y:\Int)\ra(p\,q:x=_\Int y)\ra p=_{x=_\Int y} q$.  HITs may
have constructors of iterated equality types as well. With the view of types as
spaces in mind, point constructors add points to spaces, equality constructors
add paths and higher constructors add homotopies between higher-dimensional paths.

Not all constructor expressions make sense. For example \cite[Example
  6.13.1]{HoTTbook}, given an $f:(X:\mathsf{Type})\ra X\ra X$, suppose that an
inductive type $\mathsf{Ival}$ is generated by the point constructors
$\mathsf{a}:\mathsf{Ival}$, $\mathsf{b}:\mathsf{Ival}$ and a path
constructor $\sigma:f\,\mathsf{Ival}\,\mathsf{a}
=_{\mathsf{Ival}}f\,\mathsf{Ival}\,\mathsf{b}$. The eliminator for this type
should take a motive $P:\mathsf{Ival}\ra\mathsf{Type}$, two methods $p_a :
P\,\mathsf{a}$ and $p_b : P\,\mathsf{b}$, and a path connecting
elements of $P\,(f\,\mathsf{Ival}\,\mathsf{a})$ and
$P\,(f\,\mathsf{Ival}\,\mathsf{b})$. However it is not clear what these
elements should be: we only have elements $p_a:P\,\mathsf{a}$ and
$p_b:P\,\mathsf{b}$, and there is no way in general to transform these
to have types $P\,(f\,\mathsf{Ival}\,\mathsf{a})$ and
$P\,(f\,\mathsf{Ival}\,\mathsf{b})$.

Another invalid example is an inductive type $\mathsf{Neg}$ with a constructor
$\con:(\mathsf{Neg} \ra \bot) \ra \mathsf{Neg}$ where $\bot$ is the empty
type. An eliminator for this type should (at least) yield a projection function
$\proj: \mathsf{Neg} \ra (\mathsf{Neg} \ra \bot)$. Given this, we can define $u
:\equiv \con\,(\lambda x . \proj\, x\,x):\mathsf{Neg}$ and then derive $\bot$ by
$\proj\,u\,u$. The existence of $\mathsf{Neg}$ would make the type theory
inconsistent. A common restriction to avoid such situations is \emph{strict
  positivity}. It means that the type being defined cannot occur on the left
hand side of a function arrow in a parameter of a constructor. This excludes the
above constructor $\con$.

In this paper we propose a notion of signatures for higher inductive-inductive
types (HIITs) which includes the above valid examples and excludes the invalid
ones. Our signatures allow any number of inductive-inductive type constructors,
possibly infinitary higher constructors of any dimension and restricts
constructors to strictly positive ones. It also allows free usage of $\J$ (path
induction) and $\refl$ in HIIT signatures, and allows mixing type, point and path
constructors in any order.

The core idea is to represent HIIT specifications as contexts in a
domain-specific type theory which we call the \emph{theory of signatures}. Type
formers in the theory of codes are restricted in order to enforce strict
positivity. For example, natural numbers are defined as the three-element
context
\[
  Nat:\U,\,\,\, zero:\underline{Nat},\,\,\, suc : Nat \ra \underline{Nat}
\]
where $Nat$, $zero$ and $suc$ are simply variable names, and underlining
denotes $\El$ (decoding) for the Tarski-style universe $\U$.

We also show how to derive induction and recursion principles for each
signature. We use variants of \emph{syntactic logical relation translations} to
compute notions of \emph{algebras}, \emph{homomorphisms}, \emph{displayed
  algebras} and \emph{displayed algebra sections}, and then define induction and
recursion in terms of these notions.

To our knowledge, this is the first proposal for a definition of
HIITs. However, we do not provide complete (higher) categorical semantics
for HIITs, nor do we show that initial algebras exist for specified HIITs.

\subsection{Overview of the Paper}

We start by describing the theory of HIIT signatures in Section
\ref{sec:signatures}. Here, we also describe the syntax for an external type
theory, which serves as the source of constants which are external to a
signature, like natural numbers in the case of length-indexed vectors. In
Section \ref{sec:general}, we give a general definition of induction and
recursion. In Section \ref{sec:coherence} we explain the choice of using
syntactic translations in the rest of the paper. In Sections \ref{sec:algebras}
to \ref{sec:sections}, we describe four syntactic translations from the theory
of signatures to the syntax of the external type theory, respectively computing
algebras, homomorphisms, displayed algebras and sections of displayed
algebras. In Section \ref{sec:categorical}, we consider extending the previous
translations with additional components of the categorical semantics of HIITs
(e.g.\ identity and composition for homomorphisms), and explain why the approach
in this paper does not make this feasible. Section \ref{sec:formalization}
describes the Agda formalization and the Haskell implementation. We conclude in
Section \ref{sec:summary}.

\subsection{Related Work}

Schemes for inductive families are given in
\cite{Dybjer97inductivefamilies,paulinmohring}, and for inductive-recursive
types in \cite{dybjer00ir}. A symmetric scheme for both inductive and
coinductive types is given in \cite{henning}. Basold et al. \cite{niels} define
a syntactic scheme for higher inductive types with only 0-constructors and
compute the types of induction principles. In \cite{nielsmsc} a semantics is
given for the same class of HITs but with no recursive equality
constructors. Dybjer and Moeneclaey define a syntactic scheme for finitary HITs
and show their existence in a groupoid model \cite{moeneclaey}.

Internal codes for simple inductive types such as natural numbers, lists or
binary trees can be given by containers which are decoded to W-types
\cite{abbot05containers}. Morris and Altenkirch \cite{morris09indexed} extend
the notion of container to that of indexed container which specifies indexed
inductive types. Codes for inductive-recursive types are given in
\cite{Dybjer99afinite}. Inductive-inductive types were introduced by Forsberg
\cite{forsberg-phd}. Sojakova \cite{sojakova} defines a subset of HITs called
W-suspensions by a coding scheme similar to W-types. She proves that the
induction principle is equivalent to homotopy initiality.

Quotient types \cite{hofmann95extensional} are precursors of higher inductive
types (HITs). The notion of HIT first appeared in \cite{HoTTbook}, however only
through examples and without a general definition.  Lumsdaine and Shulman give a
general specification of models of type theory supporting higher inductive types
\cite{lumsdaineShulman}. They introduce the notion of cell monad with parameters
and characterize the class of models which have initial algebras for a cell
monad with parameters. \cite{cubicalhits} develop semantics for several HITs
(sphere, torus, suspensions, truncations, pushouts) in certain presheaf toposes,
and extend the syntax of cubical type theory \cite{ctt} with these HITs. Kraus
\cite{krausprop} and Van Doorn \cite{doorn} construct propositional truncation
as a sequential colimit. The schemes mentioned so far do not support
inductive-inductive types.

Cartmell's generalized algebraic theories (GATs) \cite{gat} pioneered a
type-theoretic notion of algebraic signature. GATs can be viewed as finitary
quotient inductive-inductive signatures (QIITs), although GATs support equalities
between inductive types (sorts) as well, which have not been so far explored in
other works about QIITs and HIITs.

The article of Altenkirch et al. \cite{gabe} gives specification and semantics
of QIITs in a set-truncated setting. Signatures are given as lists of functors
which can be interpreted as complete categories of algebras, and completeness is
used to talk about notions of induction and recursion.  However, no strict
positivity restriction is given, nor a construction of initial algebras.

Closely related to the current work is the paper by the current authors and
Altenkirch \cite{kaposi2019constructing}, which also concerns QIITs. There,
signatures for QIITs are essentially a restriction of the signatures given here,
but in contrast to the current work, the restricted quotient setting enables
building initial algebras and detailed categorical semantics.

The logical predicate syntactic translation was introduced by Bernardy et
al. \cite{bernardy2010parametricity}. The idea that a context can be seen as a
signatures and the logical predicate translation can be used to derive the types
of induction motives and methods was described in \cite[Section
  5.3]{ttintt}. Logical relations are used to derive the computation rules in
\cite[Section 4.3]{kaposi-phd}, but only for closed QIITs. Syntactic
translations in the context of the calculus of inductive constructions are
discussed in \cite{next700}. Logical relations and parametricity can also be
used to justify the existence of inductive types in a type theory with an
impredicative universe \cite{atkey}.

\section{Signatures for HIITs}
\label{sec:signatures}

In this section we define signatures for HIITs. First, we list
the main motivations behind our definition.

\begin{itemize}
\item\emph{Ubiquitous type dependencies.}
Recall the inductive-inductive $\Con$-$\Ty$ example from Section
\ref{sec:intro}: there, types of constructors may refer back to previous
constructors. Additionally, $\Ty$ is indexed over the previously declared $\Con$
type constructor. This suggests that we should not attempt to stratify
signatures, and instead use a fully dependent type theory. At this level of
generality, stratification seems to complicate matters and remove the syntax
further from familiar type theories.

\item\emph{Referring to external types.}
We would like to mention types which are external to the signature. For example,
length-indexed vectors refer to natural numbers which are supposed to already
exist. Hence, we also assume a syntax for an \emph{external type theory}, which
is the source of such types, and constructions in the theory of signatures may
depend on a context in the external type theory.

\item\emph{Strict positivity.}
In prior literature, schemes for inductive types usually include structural
restrictions for this. In our case, a \emph{universe} can be used to make
size restrictions which also entail strict positivity.

\item\emph{Iterated equalities and path induction in signatures.}
We can support this relatively easily by closing the universe under equality
type formation, and also using a standard (although size-restricted) definition
of path induction.
\end{itemize}

%=====================================================================

\subsection{Theory of Signatures}
\label{sec:tos}



\begin{figure}

(1) Contexts and variables

\[
\begin{gathered}
  \infer{\hat{\Gamma}\vdash\cdot}{\vdashh\,\hat{\Gamma}}
\end{gathered}
\hspace{2em}
\begin{gathered}
  \infer{\hat{\Gamma}\vdash\Delta,x:A}{\targetass\Delta\vdash A}
\end{gathered}
\hspace{2em}
\begin{gathered}
  \infer{\targetass\Delta,x:A\vdash x : A}{\targetass\Delta\vdash A}
\end{gathered}
\hspace{2em}
\begin{gathered}
  \infer{\targetass\Delta,y:B\vdash x : A}{\targetass\Delta\vdash x : A && \targetass\Delta\vdash B}
\end{gathered}
\]

\vspace{0.5em}
(2) Universe

\[
\begin{gathered}
  \infer{\targetass\Delta \vdash \U}{\targetass\vdash\Delta}
\end{gathered}
\hspace{2em}
\begin{gathered}
  \infer{\targetass\Delta \vdash \underline{a}}{\targetass\Delta \vdash a : \U}
\end{gathered}
\]

\vspace{0.5em}
(3) Inductive parameters

\[
\begin{gathered}
  \infer{\targetass\Delta \vdash (x:a)\ra B}{\targetass\Delta \vdash a : \U && \targetass\Delta,x:\underline{a} \vdash B}
\end{gathered}
\hspace{2em}
\begin{gathered}
  \infer{\targetass\Delta \vdash t\, u : B[x \mapsto u]}{\targetass\Delta \vdash t : (x:a)\ra B && \targetass\Delta \vdash u : \underline{a}}
\end{gathered}
\]

\vspace{0.5em}
(4) Equality

\[
\begin{gathered}
  \infer{\targetass\Delta \vdash t=_a u : \U}{\targetass\Delta \vdash a : \U && \targetass\Delta \vdash t : \underline{a} && \targetass\Delta \vdash u : \underline{a}}
\end{gathered}
\hspace{2em}
\begin{gathered}
  \infer{\targetass\Delta \vdash \refl : \underline{t=_a t}}{\targetass\Delta \vdash t : \underline{a}}
\end{gathered}
\]

\[
\infer{\targetass\Delta \vdash \J_{a\,t\,\,(x.z.p)}\,pr\,_u\,eq : \underline{p[x\mapsto u, z\mapsto eq]}}
      {\begin{array}{l}
          \targetass\Delta \vdash t : \underline{a} \\
          \targetass\Delta,x:\underline{a},z:\underline{t=_a x}\vdash p : \U \\
          \targetass\Delta \vdash pr : \underline{p[x\mapsto t, z\mapsto \refl]} \\
          \targetass\Delta \vdash u : \underline{a} \\
          \targetass\Delta \vdash eq : \underline{t=_a u}
      \end{array}}
      \]

\[
\infer{\targetass\Delta \vdash \J\beta_{a\,t\,\,(x.z.p)}\,pr:\underline{(\J_{a\,t\,\,(x.z.p)}\,pr\,_t\,\refl) =_{p[x\mapsto t, z\mapsto \refl]} pr}}
      {\targetass\Delta \vdash t : \underline{a}
        && \targetass\Delta,x:\underline{a},z:\underline{t =_a x}\vdash p : \U
        && \targetass\Delta \vdash pr : \underline{p[x\mapsto t, z\mapsto \refl]}
      }
\]

\vspace{0.5em}
(5) External parameters

\[
\begin{gathered}
  \infer{\hat{\Gamma}\semicol\Delta \vdash (\hat{x}\in \hat{A})\ra B}{\hat{\Gamma}\vdashh\hat{A}\in\Type_{\hat{0}} && \hat{\Gamma}\semicol\vdash\Delta && \hat{(\hat{\Gamma}\commah\hat{x}\in \hat{A})}\semicol \Delta \vdash B}
\end{gathered}
\]

\[
\begin{gathered}
  \infer{\hat{\Gamma}\semicol\Delta \vdash t\, \hat{u} : B[\hat{x}\mapsto \hat{u}]}{\hat{\Gamma}\semicol\Delta \vdash t : (\hat{x}\in \hat{A})\ra B && \hat{\Gamma}\vdashh \hat{u} \in \hat{A}}
\end{gathered}
\]

\vspace{0.5em}
(6) Infinitary parameters

\[
\begin{gathered}
  \infer{\hat{\Gamma}\semicol\Delta \vdash (\hat{x}\in \hat{A})\ra b : \U}{\hat{\Gamma}\vdashh\hat{A}\in\Type_{\hat{0}} && \hat{\Gamma}\semicol\vdash\Delta && (\hat{\Gamma}\commah\hat{x}\in \hat{A})\semicol \Delta \vdash b : \U}
\end{gathered}
\]

\[
\begin{gathered}
  \infer{\hat{\Gamma}\semicol\Delta \vdash t\, \hat{u} : \underline{b[\hat{x}\mapsto \hat{u}]}}
        {\hat{\Gamma}\semicol\Delta \vdash t : \underline{(\hat{x}\in \hat{A})\ra b} && \hat{\Gamma}\vdash \hat{u} \in \hat{A}}
\end{gathered}
\]
\caption{The theory of HIIT signatures. Weakenings are implicit, we assume fresh
  names everywhere and consider $\alpha$-convertible terms equal. The
  $\hat{\Gamma};$ assumptions are not used or changed in parts
  (1)--(4).}
\label{sigrules}
\end{figure}

We list typing rules for the theory of signatures in Figure \ref{sigrules}. We consider the
following judgments:
\begin{alignat*}{4}
  & \hat{\Gamma}\vdash\Delta && \text{$\Delta$ is a context in the external context $\hat{\Gamma}$}\\
  & \hat{\Gamma}\semicol\Delta\vdash A && \text{$A$ is a type in context $\Delta$ and external context $\hat{\Gamma}$} \\
  & \hat{\Gamma}\semicol\Delta\vdash t : A \hspace{3em} && \text{$t$ is a term of type $A$ in context $\Delta$ and external context $\hat{\Gamma}$}
\end{alignat*}

We have the convention that constructions in the external type theory are
notated in {\color{BrickRed}brick red} color. Although every judgement is valid
up to a context in the external type theory, note that none of the rules in
(1)--(4) depend on or change these assumptions, and even after that, we do not
refer to any particular type former from the external theory. We describe the
external theory in more detail in Section \ref{sec:external}. Also, the rules
presented here are informal and optimized for readability; we describe the Agda
formalizations in Section \ref{sec:formalization}. We explain the rules for the
theory of signatures in order now.

(1) The rules for context formation and variables are standard. We build
signatures in a well-formed external context.  We assume fresh names everywhere
to avoid name capture, and leave weakenings implicit.

(2) There is a universe $\U$, with decoding written as an underline instead of
usual $\El$, to bolster readability. With this part of the syntax, we can already
define contexts specifying the empty type, unit type and booleans, or in general,
a collections of finite sets:
\[
\boldsymbol{\cdot},\,\,\,Empty:\U \hspace{3em} \boldsymbol{\cdot},\,\,\,Unit:\U,\,\,\,tt:\underline{Unit} \hspace{3em} \boldsymbol{\cdot},\,\,\,Bool:\U,\,\,\,true:\underline{Bool},\,\,\,false:\underline{Bool}
\]

(3) We have a function space with small domain and large codomain. This can be
used to add inductive arguments to all kinds of constructors. As $\U$ is not
closed under this function space, these function types cannot (recursively)
appear in inductive arguments, which ensures strict positivity. When the
codomain does not depend on the domain, $a\ra B$ can be written instead of
$(x:a)\ra B$.

Now we can specify the natural numbers as a context:
\[
\boldsymbol{\cdot},\,\,\,Nat : \U,\,\,\,zero:\underline{Nat},\,\,\,suc:Nat\ra\underline{Nat}
\]
We can also encode inductive-inductive definitions such as the
fragment of the well-typed syntax of a type theory mentioned in the
introduction:
\begin{alignat*}{5}
  & \boldsymbol{\cdot},\,\,\,Con:\U,\,\,\,Ty:Con\ra\U,\,\,\,\bullet:\underline{Con},\,\,\,\blank\rhd\blank:(\Delta:Con)\ra Ty\,\Delta\ra\underline{Con}, \\
  & U : (\Delta:Con)\ra \underline{\Ty\,\Delta},\,\,\,\Pi:(\Delta:Con)(A:Ty\,\Delta)(B:Ty\,(\Delta\rhd A))\ra\underline{Ty\,\Delta}
\end{alignat*}
Note that this notion of inductive-inductive types is more general than the one
considered in previous works \cite{forsberg-phd}, as we allow any number of type
constructors, and arbitrary mixing of type and point constructors.

(4) $\U$ is closed under the equality type, with eliminator $\J$ and a weak
(propositional) $\beta$-rule. Weakness is required because the translations in
Sections \ref{sec:morphisms} and \ref{sec:sections} do not preserve this
$\beta$-rule strictly. We explain this in more detail in Sections TODO and
TODO. Adding equality to the theory of codes allows higher constructors and
inductive equality parameters as well. We can now define the higher-inductive
circle as the following context:
\[
\boldsymbol{\cdot},\,\,\,S^1:\U,\,\,\,base:\underline{S^1},\,\,\,loop:\underline{base =_{S^1} base}
\]

The $\J$ rule allows constructors to mention operations on paths as well. For
instance, the definition of the torus depends on path composition, which can be
defined using $\J$: given $p:\underline{t=_a u}$ and $q:\underline{u=_a v}$, $p
\sqcdot q$ abbreviates $\J_{a\,u\,x.z.(t=x)}\,p\,_v\,q : \underline{t=_a
  v}$. The torus is given as follows.
\begin{alignat*}{5}
  & \boldsymbol{\cdot},\,\,\,T^2:\U,\,\,\,b : \underline{T^2},\,\,\, p:\underline{b =_{T^2} b},\,\,\,q:\underline{b=_{T^2} b},\,\,\, t:\underline{p\sqcdot q=_{(b=_{T^2} b)} q\sqcdot p}
\end{alignat*}
With the equality type at hand, we can define a full well-typed syntax of type
theory as given e.g.\ in \cite{ttintt} as an inductive type.  Also, see the
examples in the Agda formalization described in Section
\ref{sec:formalization}.

So far we were only able to define closed HIITs, which do not refer to external
types. Now we add rules which include external types into signatures. A context
$\Delta$ for which $\hat{\Gamma}\vdash\Delta$ holds can be seen as a
specification of an inductive type which depends on $\hat{\Gamma}$. For example,
in the case of lists for arbitrary external element types, $\hat{\Gamma}$ will
be $\hat{A}\in\Type_{\hat{0}}$.

(5) We have a function space where the domain is a type in the external theory. We
distinguish it from (3) by using red brick $\in$ instead of $:$ in the domain
specification. We specify lists and the integers as follows.
\begin{alignat*}{4}
  & \hat{A}\in\Type_{\hat{0}} && \vdash\,\boldsymbol{\cdot},\,\, && List:\U,\,\,\,nil:\underline{List},\,\,\,cons:(\hat{x}\in \hat{A})\ra List\ra\underline{List} \\
  & \hat{\Gamma} && \vdash\,\boldsymbol{\cdot},\,\,&& Int:\U,\,\,\,pair:(\hat{x}\,\hat{y}\in\hat{Nat})\ra\underline{Int},\,\,\, \\
  & && && eq:(\hat{a}\,\hat{b}\,\hat{c}\,\hat{d}\in \hat{Nat})(\hat{p}\in \hat{a}\hat{\mathbin{+}}\hat{d}\eqh_{\hat{Nat}} \hat{b}\hat{\mathbin{+}}\hat{c})\ra \underline{pair\,\hat{a}\,\hat{b}=_{Int}\mathsf{pair}\,\hat{c}\,\hat{d}}, \\
  & && && trunc:(x y : Int)(p\,q : a=_{Int} b)\ra \underline{p=_{x=_{Int} y} q}
\end{alignat*}
In the case of integers, $\hat{\Gamma}$ is
$\hat{Nat}\in\Type_{\hat{0}}\hat{,}\,\blank\hat{\mathbin{+}}\blank\in\hat{Nat}\rah
\hat{Nat}\rah\hat{Nat}$, or alternatively, we could require natural
numbers in the external theory. As another example, propositional
truncation for a type $\hat{A}$ is specified as follows.
\[
\hat{A}\in\Type_{\hat{0}}\vdash\, \boldsymbol{\cdot},\,\,\,tr:\U,\,\,\,emb : (\hat{x}\in \hat{A})\ra \underline{tr},\,\,\,eq:(x\,y:tr)\ra \underline{x=_{tr} y}
\]
The smallness of $\hat{A}$ is required in (5). It is possible to generalize
signatures to arbitrary universe levels, but it is not essential to the current
development. Note that the (5) function space preserves strict positivity, since
in the external theory there is no way to recursively refer to the inductive type
\emph{being defined}. The situation is analogous to the case of $W$-types
\cite{abbot05containers}, where shapes and positions can contain arbitrary types
but they cannot recursively refer to the $W$-type being defined.

(6) $\U$ is also closed under a function space where the domain is an external
type and the codomain is a small source theory type. We overload the application
notation for external parameters, as it is usually clear from context which
application is meant. The rules allow types with infinitary constructors, for
example trees containing elements of $\hat{A}$ at the leaves and branching by
$\hat{B}$ (which could be an infinite type):
\[
\hat{A}\in\Type_{\hat{0}}\commah\hat{B}\in\Type_{\hat{0}}\vdash\,\boldsymbol{\cdot},\,\,\,T:\U,\,\,\,leaf:(\hat{x}\in \hat{A})\ra\underline{T},\,\,\,node:((\hat{x}\in \hat{B})\ra T)\ra\underline{T}
\]
Here, $leaf$ has a function type (5) and $node$ has a function type (3) with a
function type (6) in the domain. More generally, we can define $W$-types
\cite{abbot05containers} as follows. $\hat{S}$ describes the ``shapes'' of the
constructors and $\hat{P}$ the ``positions'' where recursive arguments can
appear.
\[
\hat{S}\in\Type_{\hat{0}}\commah\hat{P}:\hat{S}\rah\Type_{\hat{0}}\vdash\,\boldsymbol{\cdot},\,\,\,W:\U,\,\,\,sup: (\hat{s} \in \hat{S})\ra((\hat{p} \in \hat{P}\,\hat{s})\ra W)\ra \underline{W}
\]
For a more complex infinitary example, see the definition of Cauchy
reals in \cite[Definition 11.3.2]{HoTTbook}. It can be also found as
an example file in our Haskell implementation.

The invalid examples $\mathsf{Ival}$ and $\mathsf{Neg}$ from Section
\ref{sec:intro} cannot be encoded by the theory of codes. For $\mathsf{Ival}$,
we can go as far as
\[
\boldsymbol{\cdot},\,\,\,{Ival}:\U,\,\,\,a:\underline{{Ival}},\,\,\,b:\underline{{Ival}},\,\,\,\sigma:\underline{?  =_{{Ival}} ?}.
\]
The first argument of the function
$\hat{\hat{f}\in(\hat{X}:\Type)\rah\hat{X}\rah\hat{X}}$ is an external type, but we
only have ${Ival}:\U$ in the theory of codes. $\mathsf{Neg}$ cannot be typed
because the first parameter of the constructor $\mathsf{con}$ is a function from
a small type to an external type, and no such functions can be formed.


\subsection{External type theory}
\label{sec:external}

The external syntax serves two purposes: it is a source of types external to a
HIIT signature, and it also serves as the target for the syntactic translations
described in Sections \ref{sec:algebras} to \ref{sec:sections}. It is not
essential that we use the same theory for both purposes; we do so only to
simplify the presentation by skipping an additional translation or embedding
step. Also, we do not specify the external theory in formal detail, since it is
a standard type theory. We only make some assumptions about supported type
formers. We generally keep the notation close to Agda, and use
{\color{BrickRed}brick red} color to distinguish from constructions in the
theory of signatures.

There is a cumulative Russell-style hierarchy of universes $\Type_{\hat{i}}$,
with universes closed under $\Pi$, $\Sigma$, equality and unit
types. Importantly, we do not assume uniqueness of identity proofs.

The unit type is denoted $\hat{\top}$ with constructor $\tt$.

Dependent function space is denoted $\hat{(\hat{x}\in \hat{A})\rah \hat{B}}$. We
write $\hat{A}\rah \hat{B}$ if $\hat{B}$ does not depend on $\hat{x}$, and $\rah
$ associates to the right, $\hat{(\hat{x}\in \hat{A})(\hat{y}\in \hat{B})\rah
  \hat{C}}$ abbreviates $\hat{(\hat{x}\in \hat{A})\rah (\hat{y}\in \hat{B})\rah
  \hat{C}}$ and $\hat{(\hat{x}\,\hat{y}\in \hat{A})\rah \hat{B}}$ abbreviates
$\hat{(\hat{x}\in \hat{A})(\hat{y}\in \hat{A})\rah \hat{B}}$. We write
$\hat{\lambda x. t}$ for abstraction and $\hat{t}\,\hat{u}$ for left-associative
application.

$\hat{(\hat{x}\in \hat{A})\timesh \hat{B}}$ stands for $\Sigma$ types, $\hat{A}\timesh
\hat{B}$ for the non-dependent version. We sometimes use a short re-associated
notation for left-nested iterated $\Sigma$ types, for example $\hat{(A :
  \Type_{\hat{0}})\times A \times A}$ may stand for the left-nested $\hat{(x :
  (A : \Type_{\hat{0}})\times A) \times \proj_1\,A}$. The constructor for
$\Sigma$ is denoted $\hat{(t,\,u)}$ with eliminators $\hat{\proj_1}$
and $\hat{\proj_2}$. Both $\Pi$ and $\Sigma$ have definitional $\beta$ and
$\eta$ rules.

The equality type for a type $\hat{A}$ and elements $\hat{t}\in \hat{A}$,
$\hat{u}\in \hat{A}$ is denoted $\hat{t}\eqh_{\hat{A}}\hat{u}$, and we have the
constructor $\hat{\refl}_{\hat{t}}$ and the eliminator $\hat{\J}$ with
definitional $\beta$-rule. The notation is
$\hat{\J}_{\hat{A}\,\hat{t}\,\hat{P}}\,\hat{pr}\,_{\hat{u}}\,\hat{eq}$ for
$\hat{t}\in \hat{A}$, $\hat{P}\in (\hat{x}\in \hat{A})\rah
\hat{t}\eqh_\hat{A}\hat{x}\rah \Type_{\hat{i}}$, $\hat{pr}\in
\hat{P}\,\hat{t}\,\hat{\refl}$ and $\hat{eq} \in
\hat{t}\eqh_\hat{A}\hat{u}$. Sometimes we omit parameters in subscripts.

We will use the following functions defined using $\hat{\J}$ in the standard
way. We write $\TR_{\hat{P}}\,\hat{e}\,\hat{t}\in \hat{P}\,\hat{v}$ for
transport of $\hat{t} \in \hat{P}\,\hat{u}$ along $\hat{e} \in \hat{u}\eqh
\hat{v}$. We write
$\ap\,\hat{f}\,\hat{e}\in\hat{f}\,\hat{u}\eqh\hat{f}\,\hat{v}$ where
$\hat{f}:\hat{A}\rah\hat{B}$ and $\hat{e}\in\hat{u}\eqh\hat{v}$, also
$\hat{\apd\,\hat{f}\,\hat{e} \in \TR_{\hat{P}}\,\hat{e}\,(\hat{f}\,\hat{u}) \eqh
  \hat{f}\,\hat{v}}$ where $\hat{\hat{f}\in(\hat{x}\in \hat{A})\rah \hat{B}}$
and $\hat{e} \in \hat{u}\eqh \hat{v}$. Borrowing notation from the homotopy type
theory book \cite{HoTTbook}, we write $\hat{p \sqcdot q}$ for transitivity and
$\hat{p^{-1}}$ for symmetry. We also make use of the groupoid law $\hat{\inv\,p
  : p^{-1}\sqcdot p = \refl}$.


%=====================================================================

\section{General Definitions for Induction and Recursion}
\label{sec:general}

Armed with a definition for HIIT signatures, we would like to have of notions of
\emph{induction} and \emph{recursion} for each signature. However, instead of
trying to directly extract them from signatures, it is more helpful to have more
fundamental (categorical) semantic concepts: \emph{algebras},
\emph{homomorphisms}, \emph{displayed algebras} and \emph{sections of displayed
  algebras}. Then, we can express induction and recursion using these.

Let us first consider natural numbers, and see how the usual definition of
induction arises.

For $\Nat$, algebras are simply a triple consisting of a type, a value and an
endofunction. Below, we leave universe indices explicit, and we use the notation
of the external type theory described in Section \ref{sec:external}.
\begin{alignat*}{5}
& \Alg : \mathsf{Type} \\
& \Alg \equiv (N : \mathsf{Type}) \times N \times (N \ra N)
\end{alignat*}

\noindent Displayed $\Nat$-algebras (sometimes called fibered algebras, as in
\cite{sojakova}) are likewise triples, but each component depends on the
corresponding components of a $\Nat$-algebra. We borrow the term ``displayed''
from Ahrens and Lumsdaine \cite{displayedCategories}, as our displayed algebras
generalize their displayed categories.
\begin{alignat*}{5}
& \DisplayedAlg : \Alg \ra \mathsf{Type} && \\
& \DisplayedAlg\,(N,\,z,\,s) \equiv && \\
&  \hspace{3em} (N^D : N \ra \mathsf{Type})\times (z^D : N^D\,z)\times ((n : N)\ra N^D\,n\ra N^D\,(s\,n))
\end{alignat*}

\noindent  Homomorphisms, as usual in mathematics, are structure-preserving functions:
\begin{alignat*}{5}
& \Morphism : \Alg \ra \Alg \ra \mathsf{Type} && \\
& \Morphism\,(N_0,\,z_0,\,s_0)\,(N_1,\,z_1,\,s_1) \equiv && \\
&  \hspace{3em} (N^M : N_0 \ra N_1)\times (z^M : N^M\,z_0 = z_1)\times ((n : N_0)\ra N^M\,(s_0\,n) = s_1\,(N^M\,n))
\end{alignat*}

\noindent Sections of displayed algebras can be viewed as a dependently typed analogue of homomorphisms:
\begin{alignat*}{5}
& \Section : (\alpha : \Alg) \ra \DisplayedAlg\,\,\alpha \ra \mathsf{Type} && \\
& \Section\,(N,\,z,\,s)\,(N^D,\,z^D,\,s^D) \equiv && \\
&  \hspace{3em} (N^S : (n : N) \ra N^D\,n)\times (z^S : N^S\,z = z^D)\times ((n : N)\ra N^S\,(s\,n) = s^D\,n\,(N^S\,n))
\end{alignat*}

\noindent Now, we can reformulate induction for $\Nat$. First, we assume that
there exists a distinguished $\Nat$-algebra, named $\mathsf{InitialAlg}$. The
induction principle has the following type:
\[
 \mathsf{Induction} : (M : \mathsf{\DisplayedAlg}\,\,\mathsf{InitialAlg}) \ra \Section\, M
\]
\noindent Unfolding the definitions, it is apparent that this is the same notion
of $\Nat$-induction as we gave before. The initial algebra consists of type and value
constructors, the induction motives and methods are bundled into a displayed
algebra, and as result we get a section, containing an eliminator function together
with its $\beta$-rules. Additionally, we can define recursion using homomorphisms:
\[
\mathsf{Recursion} : (\alpha : \Alg) \ra \Morphism\,\mathsf{InitialAlg}\,\alpha
\]
This corresponds to \emph{weak initiality} in the sense of category theory: for
each algebra, there is a morphism from the weakly initial algebra to it. Strong initiality
in the setting of higher inductive types is called \emph{homotopy initiality} \cite{sojakova},
and it is defined as follows for $\Nat$:
\begin{alignat*}{5}
\mathsf{Initiality} : (\alpha : \Alg) \ra \mathsf{isContr}\,(\Morphism\,\mathsf{InitialAlg}\,\alpha)
\end{alignat*}

\noindent where $\mathsf{isContr}\,A \equiv (a : A)\times((a' : A)\ra a = a')$. Hence, there is a unique morphism from the initial algebra, but in the setting of homotopy type theory, unique inhabitation can be viewed instead as contractibility.

Observe that the definitions for $\mathsf{Induction}$, $\mathsf{Recursion}$ and
$\mathsf{Initiality}$ need not refer to natural numbers, and can be used
similarly in cases of other structures. Thus, the task in the following is to
derive algebras, homomorphisms, displayed algebras and sections from HIIT
signatures, in a way which generalizes beyond the current $\Nat$ example to
indexed types, induction-induction and higher constructors. But even in the
general case, displayed algebras yield induction motives and methods, and
homomorphisms and sections yield a function for each type constructor and a
$\beta$-rule for each point or path constructor.

We will compute algebras and the other notions by induction on the syntax of the
theory of signatures. However, first we need to clarify the formal foundations
of these computations.

\section{The Coherence Problem and Syntactic Translations}
\label{sec:coherence}

The next task would be to define a computation which takes as input a
$\hat{\Gamma}\vdash\Delta$ signature, and returns the corresponding type of
algebras in some type theory. This would behave as a ``standard'' model of
signatures, which simply maps each construction in the syntax to its
counterpart: types to types, universe to universe, functions to functions, and
so on.

However, it is important to interpret signatures into a theory without
uniqueness of identity proofs (UIP), because we are considering \emph{higher}
inductive types, and hence must remain compatible with higher-dimensional
interpretations. In particular, we need to interpret type constructors in
signatures into type universes which are not truncated to any homotopy level. In
this setting, even the mundane $\alpha : (N : \mathsf{Type}) \times N \times (N
\ra N)$ natural number algebras may have arbitrary higher-dimensional structure.

On first look, we might think that the simplest way to formalize the algebra
interpretation is the following:
\begin{enumerate}
\item Assume as metatheory a type theory without UIP.
\item In this setting, define a formal syntax of the theory of signatures.
\item Give a standard interpretation of signatures into the UIP-free metatheory.
\end{enumerate}

It may come as a surprise that realizing the above steps is an \emph{open
  problem}, for any syntax of a dependent type theory. We call the problem of
interpreting syntaxes of type theories into a UIP-free metatheory a
\emph{coherence problem}. This issue appears to arise with all known ways of
defining syntaxes for dependent type theories.

In the following, we first consider the coherence problem in two settings: with
intrinsically typed higher inductive-inductive syntaxes, then with conventional
syntaxes involving preterms and inductively defined typing and conversion
relations. Then, we present syntactic translations as a partial solution to the
coherence problem.

\subsection{Interpreting intrinsic syntax}
Following Altenkirch and Kaposi \cite{ttintt}, one might define the syntax of a
type theory as an initial category with families (CwF) \cite{dybjer1995internal}
extended with additional type formers. The CwF part provides a calculus and
equational theory for explicit substitutions, upon which one can build
additional type structure. We present an excerpt below:

\begin{alignat*}{5}
  & \Con && : \Set && \text{contexts} \\
  & \Ty  && : \Con\ra\Set && \text{types} \\
  & \Sub  && : \Con\ra\Con\ra\Set && \text{substitutions} \\
  & \Tm  && : (\Gamma:\Con)\ra\Ty\,\Gamma\ra\Set \hspace{2em} && \text{terms} \\
  & \cdot && : \Con && \text{empty context} \\
  & \blank\rhd\blank && : (\Gamma:\Con)\ra\Ty\,\Gamma\ra\Con && \text{context extension} \\
  & \blank[\blank] && : \Ty\,\Delta\ra\Sub\,\Gamma\,\Delta\ra\Ty\,\Gamma && \text{type substitution} \\
  & \id && : \Sub\,\Gamma\,\Gamma && \text{identity substitution} \\
  & [\id] && : A[\id] = A && \text{action of}\,\,\id\,\,\text{on types}\\
  & \blank\circ\blank && : \Sub\,\Theta\,\Delta\ra\Sub\,\Gamma\,\Theta\ra\Sub\,\Gamma\,\Delta && \text{substitution composition} \\
  & \blank[\blank] && : \Tm\,\Delta\,A\ra(\sigma:\Sub\,\Gamma\,\Delta)\ra\Tm\,\Gamma\,(A[\sigma])\hspace{1em} && \text{term substitution} \\
  & ... && \\
  & \U && : \Ty\,\Gamma && \text{universe} \\
  & {\U[]} && : \U[\sigma] = \U && \text{substituting the universe} \\
  & \El && : \Tm\,\Gamma\,\U \ra \Ty\,\Gamma && \text{decoding} \\
  & \Pi && : (A:\Ty\,\Gamma)\ra\Ty\,(\Gamma\rhd A)\ra\Ty\,\Gamma && \text{functions} \\
  & ... &&
\end{alignat*}

This notion of syntax is much more compact and often much more convenient to use
than extrinsic syntaxes. It is in essence ``merely'' a formalization of CwFs,
which are often used in categorical semantics of type theory. However, its
rigorous metatheory is subject to ongoing research (including the current
paper). In a set-truncated setting, the current authors and Altenkirch have
previously developed semantics and constructed initial algebras
\cite{kaposi2019constructing}, but here we need to work in a non-truncated
theory.

\subsubsection{Set-truncation}
Additionally, we need to set-truncate the syntax by adding the following constructors:
\begin{alignat*}{5}
  & \mathsf{setTy}  && : (A\,B : \Ty\,\Gamma)(p\,q : A = B)\ra p = q \\
  & \mathsf{setTm}  && : (t\,u : \Tm\,\Gamma\,A)(p\,q : t = u)\ra p = q \\
  & \mathsf{setSub} && : (\sigma\,\delta : \Sub\,\Gamma\,\Delta)(p\,q : \sigma = \delta)\ra p = q
\end{alignat*}

\noindent We can omit the rule for contexts, as it is derivable from the above ones. Set
truncation forces definitional equality of the syntax (as defined by equality
constructors in the HIIT signature) to be proof irrelevant. If we omit
set-truncation, then the defined HIIT becomes very different from what we expect
the syntax to be.

We can easily show that the non-truncated syntax does not form sets. For
example, $\U[]$ and $[\id]$ are two proofs of $\U[\id] = \U$, and they are not
forced to be equal. Assuming univalence, we can give a model where types are
interpreted as closed metatheoretic types, $\U$ is interpreted as metatheoretic
$\Bool$, $[\id]$ is interpreted as $\refl : A = A$ for some metatheoretic $A$
type, and $\U[]$ is interpreted as the $\Bool$ negation equivalence, thereby
formally distinguishing $\U[]$ and $[\id]$. Hence, by Hedberg's theorem
\cite{hedberg}, the syntax does not have decidable equality. This also implies
that the non-truncated intrinsic syntax is not constructible from set quotients
of extrinsic terms (since those always form sets). The non-truncated syntax just
does not seem to be a sensible notion. This situation is similar to how
categories in homotopy type theory need to have set-truncated objects
\cite{ahrens2015univalent}.

Unfortunately, set-truncation makes it impossible to directly interpret
syntactic types as elements of a UIP-free metatheoretic $\mathsf{Type}_i$
universe. This is because we must provide interpretations for all set-truncation
constructors, which amounts to shoving that the interpretations of $\Ty$,
$\Con$, $\Sub$ are all sets. However, we cannot show $\mathsf{Type}_i$ to be a
set without UIP.

A possible solution would be to add \emph{all higher coherences} instead of
set-truncating, which would yield something like an ($\omega$, 1)-CwF, but this
is also an open research problem \cite{altenkirch2018towards, finster2019structure}.

\subsection{Interpreting extrinsic syntax}
An extrinsic syntax for type theory is defined the following way:
\begin{enumerate}
\item We inductively define a \emph{presyntax}: sets of preterms, pretypes,
      precontexts, and possibly presubstitutions. These are not assumed to
      be well-formed, and only serve as raw material for expressions.
\item We give mutual inductive definitions for the following relations on presyntax:
      well-formedness, typing and conversion.
\end{enumerate}

This is the conventional way of presenting the syntax; see
e.g.\ \cite{winterhalter2019eliminating} for a detailed machine-checked
formalization in this style. The main advantage compared to the intrinsic syntax
is that this only requires conservative inductive definitions in the metatheory,
which are also natively supported in current proof assistants, unlike HIITs. The
main disadvantage is verbosity, lower level of abstraction, and a difficulty of
pinning down a notion of model for the syntax.

What about interpreting extrinsic syntax into a UIP-free universe? It is widely
accepted that extrinsic syntaxes have standard interpretations in set-truncated
metatheories, although carrying this out in formal detail is technically
challenging. Streicher's seminal work \cite{streicher2012semantics} laid out a
template for doing this: first we construct a family of partial functions from
the presyntax to the semantic domain, then we prove afterwards that these
functions are total on well-formed input.

However, the coherence problem arises still: it is required that definitional
equality is proof irrelevant. In a type-theoretic setting, this means that we
need to propositionally truncate the conversion relation. This again prevents us
from interpreting the syntax into a UIP-free universe. We have to interpret
definitional equality in the syntax as propositional equality in the metatheory,
but since the former is propositionally truncated, we can only eliminate it into
propositions, and metatheoretic equality types are not generally propositions in
the absence of UIP.

Could we define a conversion relation which is propositional, but not truncated?
For example, conversion could be defined in terms of a deterministic conversion
checking algorithm. But then a complication is that we do not have a proof that
conversion checking is \emph{total} and \emph{stable under substitution}, while
still in the process of defining the syntax.

Alternatively, we could first define a normalization algorithm for an extrinsic
syntax in a UIP-free metatheory, and then try to interpret \emph{only normal
  forms}. Abel, \"Ohman and Vezzosi demonstrated a UIP-free conversion checking
algorithm in type theory \cite{abel2017decidability}, which suggests that
UIP-free normalization may be possible as well. But since this normal form
interpretation is a major technical challenge, and it has not been carried out
yet, we cannot use it to justify constructions in the current paper.

\subsection{Syntactic translations}
We can circumvent the coherence problem in the following way:
\begin{enumerate}
\item Define a \emph{source} and a \emph{target} syntax in any suitable metatheory,
      where the target theory does not have UIP. The source and target theories
      do not necessarily need to differ.
\item Interpret the source syntax into the target syntax.
\end{enumerate}

For extrinsic syntaxes, it is generally understood that a syntactic translation
has to preserve definitional equalities in the source syntax. For intrinsic
syntaxes, preservation of definitional equality is automatically enforced by the
equality constructors. See Boulier et al.\ \cite{next700} for a showcase of
syntactic translations.

Now, we can take the source syntax to be the theory of signatures from Section
\ref{sec:tos}, and the target syntax to be the external syntax from Section
\ref{sec:external}. Truncation in the source syntax is not an issue here,
because the target syntax is likewise truncated, so we can translate into it.

However, using syntactic translations is also a significant restriction. As
always, we must map equal inputs to equal outputs, but now the notion of
equality for outputs coincides with definitional equality in the syntax of the
target theory, which is far more restrictive than propositional equality. Recall
the weak $\beta$-rule for $\J$ in the theory of signatures in Section
\ref{sec:tos}: if we instead used a strict equality, then the translations in
Sections \ref{sec:morphisms} and \ref{sec:sections} would not work, because they
map $\J_{a\,t\,\,(x.z.p)}\,pr\,_t\,\refl$ and $pr$ to terms which are equal
propositionally, but not definitionally. This restriction also prevents us from
defining more translations which cover other parts of the categorical
semantics, e.g.\ composition of homomorphisms. We return to this topic in
Section \ref{sec:categorical}.

In the following three sections we present syntactic translations yielding
algebras, homomorphisms, displayed algebras and their sections. The presentation
here is informal and focuses on readability, similarly to our presentation of
signatures before.


\section{Algebras}
\label{sec:algebras}

We use $\blank^\A$ to the denote the translation which computes algebras. It is
specified as follows, for contexts, types and terms in the theory of signatures.

\[
\infer{\hat{\Gamma}\vdashh\Delta^\A\in\Type_{\hat{1}}}{\hat{\Gamma}\vdash\Delta}
\hspace{2em}
\infer{\hat{\Gamma}\vdashh A^\A \in \Delta^\A\rah \Type_{\hat{1}}}{\hat{\Gamma}\semicol\Delta\vdash A}
\hspace{2em}
\infer{\hat{\Gamma}\vdashh t^\A \in \hat{(}\hat{\gamma}\in\Delta^\A\hat{)}\rah  A^\A\,\hat{\gamma}}{\hat{\Gamma}\semicol\Delta\vdash t : A}
\]

The $\blank^\A$ translation is essentially the standard interpretation of
signatures, where every construction in the source syntax is interpreted with a
corresponding {\color{BrickRed}brick red} construction in the target syntax. The
only notable change is in the interpretation of contexts: a source context is
interpreted as an iterated $\Sigma$-type.

\begingroup
\allowdisplaybreaks
\begin{alignat*}{5}
  & \boldsymbol{\cdot}^\A && :\equiv \hat{\top} \\
  & (\Delta,x:A)^\A && :\equiv \hat{(}\hat{\gamma}\in\Delta^\A\hat{)}\timesh A^\A\,\hat{\gamma} \\
  & x^\A\,\hat{\gamma} && :\equiv x^{\text{th}}\text{ component in } \hat{\gamma} \\ % TODO: write De Bruijn versions
  & \U^\A\,\hat{\gamma} && :\equiv \Type_{\hat{0}} \\
  & (\underline{a})^\A\,\hat{\gamma} && :\equiv a^\A\,\hat{\gamma} \\
  & ((x:a)\ra B)^\A\,\hat{\gamma} && :\equiv \hat{(}\hat{x}\in a^\A\,\hat{\gamma}\hat{)}\rah  B^\A\,\hat{(}\hat{\gamma}\commah\hat{x}\hat{)} \\
  & (t\,u)^\A\,\hat{\gamma} && :\equiv \hat{(}t^\A\,\hat{\gamma}\hat{)}\,\hat{(}u^\A\,\hat{\gamma}\hat{)} \\
  & ((\hat{x}\in \hat{A})\ra B)^\A\,\hat{\gamma} && :\equiv \hat{(}\hat{x}\in \hat{A})\rah  B^\A\,\hat{\gamma} \\
  & (t\,\hat{u})^\A\,\hat{\gamma} && :\equiv \hat{(}t^\A\,\hat{\gamma}\hat{)}\,\hat{u} \\
  & (t=_a u)^\A\,\hat{\gamma} && :\equiv t^\A\,\hat{\gamma} \eqh u^\A\,\hat{\gamma} \\
  & \refl^\A\,\hat{\gamma} && :\equiv \hat{\refl} \\
  & (\J_{a\,t\,(x.z.p)}\,pr\,_u\,eq)^\A\,\hat{\gamma} && :\equiv \hat{\J}_{\hat{(}a^\A\,\hat{\gamma}\hat{)}\,\hat{(}t^\A\,\hat{\gamma}\hat{)}\,\hat{(}\hat{\lambda} \hat{x}\,\hat{z}.p^\A\,\hat{(}\hat{\gamma}\commah\hat{x}\commah\hat{z}\hat{)}\hat{)}}\,\hat{(}pr^\A\,\hat{\gamma}\hat{)}\,_{\hat{(}u^\A\,\hat{\gamma}\hat{)}}\,\hat{(}eq^\A\,\hat{\gamma}\hat{)} \\
  & (\J\beta_{a\,t\,(x.z.p)}\,pr)^\A\,\hat{\gamma} && :\equiv \hat{\refl} \\
  & ((\hat{x}\in \hat{A})\ra b)^\A\,\hat{\gamma} && :\equiv (\hat{x}\in \hat{A}\hat{)}\rah  b^\A\,\hat{\gamma} \\
  & (t\,\hat{u})^\A\,\hat{\gamma} && :\equiv \hat{(}t^\A\,\hat{\gamma}\hat{)}\,\hat{u}
\end{alignat*}
\endgroup

For example, $\blank^\A$ acts as follows on signature for circles:
\begin{alignat*}{5}
  & && (\boldsymbol{\cdot},\,S^1 : \U,\,b:\underline{S^1},\,loop: \underline{b=b})^\A \equiv \hat{\hat{\top}\timesh(\hat{S^1}\in\Type_{\hat{0}})\timesh(\hat{b}\in \hat{S^1})\timesh(\hat{loop\in b=b})}
\end{alignat*}

Note that the resulting $\Sigma$ type is left-nested, and we use the reassociated notation for readability. The result could be written without syntactic sugar the following way:
\begin{alignat*}{5}
  & \hat{\Big(\hat{x''}\in\big(\hat{x'}\in(\hat{x}\in\hat{\top})\timesh\Type_{\hat{0}}\big)\timesh\hat{\proj_2}\,\hat{x'}\Big)\timesh(\hat{\proj_2}\,\hat{x''}\eqh \hat{\proj_2}\,\hat{x''})}
\end{alignat*}
We shall keep to the short notation from now on.

%---------------------------------------------------------------------

\section{From Logical Relations to Homomorphisms}
\label{sec:morphisms}

In this section, we specify the $\blank^\M$ translation, which computes
homomorphisms of algebras. However, it is illustrative to first consider a
logical relation interpretation, and move to homomorphisms from that. For
dependent type theories, logical relation models are well-known (see
e.g.\ \cite{atkey}), so they are certainly applicable to our restricted syntax
as well.

Below, we list induction motives for $\blank^\M$; these remain the same as we
move from logical relations to homomorphisms. We fix a universe level $\hat{i}$ for
the translations.
\[
\infer{\hat{\Gamma}\vdashh\Delta^\M \in \Delta^\A\rah\Delta^\A\rah \Type_{\hat{i}}}
      {\hat{\Gamma}\vdash\Delta}
\hspace{1em}
\infer{
  \hat{\Gamma}\vdashh A^\D \in \hat{(}\hat{\gamma_0\,\gamma_1}\in\Delta^\A\hat{)}\rah \Delta^\M\,\hat{\gamma_0\,\gamma_1}\rah  A^\A\,\hat{\gamma_0}\rah A^\A\,\hat{\gamma_1}\rah \Type_{\hat{i}}}
      {\hat{\Gamma}\semicol\Delta\vdash A}
\]

\[
\infer{
  \hat{\Gamma}\vdashh A^\D \hat{ : (\gamma_0\,\gamma_1 : \blc{\Delta^\A})(\gamma^M : \blc{\Delta^\M}\,\gamma_0\,\gamma_1)\ra \blc{A^\M}\,\gamma_0\,\gamma_1\,\gamma^M\,(\blc{t^\A}\,\gamma_0)\,(\blc{t^\A}\,\gamma_1)
      }}
      {\hat{\Gamma}\semicol\Delta\vdash t : A}
\]


Contexts are mapped to (proof-relevant) relations and types to families of relations
depending on interpreted contexts. For terms, we get something which is often called
a \emph{fundamental theorem} of a logical relation: every term is related to itself
in related semantic contexts.

We present below the logical relation interpretation only for contexts, variables,
the universe and the inductive function space.

\begingroup
\allowdisplaybreaks
\begin{alignat*}{5}
  & \boldsymbol{\cdot}^\M\hat{\gamma_0\,\gamma_1} && :\equiv \hat{\top} \\
  & (\Delta,x:A)^\M\,\hat{\gamma_0\,\gamma_1} && :\equiv \hat{(\gamma^M : \blc{\Delta^\M}\,\gamma_0\,\gamma_1)\times \blc{A^\M}\,\gamma_0\,\gamma_1\,\gamma^M} \\
  & x^\M\,\hat{\gamma_0\,\gamma_1\,\gamma^M} && :\equiv x^{\text{th}}\text{ component in } \hat{\gamma^M} \\
  & \U^\M\,\hat{\gamma_0\,\gamma_1\,\gamma^M\,A_0\,A_1} && :\equiv \hat{A_0\ra A_1 \ra \Type_0} \\
  & (\underline{a})^\M\,\hat{\gamma_0\,\gamma_1\,\gamma^M\,t_0\,\,t_1} && :\equiv \hat{
    \blc{a^\M}\,\gamma_0\,\gamma_1\,\gamma^M\,t_0\,\,t_1}\\
  & ((x:a)\ra B)^\M\,\hat{\gamma_0\,\gamma_1\,\gamma^M\,f_0\,f_1} && :\equiv
  \hat{(x_0 : \blc{(\underline{a})^\A}\,\gamma_0)(x_1 : \blc{(\underline{a})^\A}\,\gamma_1)(x^M : \blc{(\underline{a})^\M}\,\gamma_0\,\gamma_1\,\gamma^M)}\\
  & && \hat{\hspace{1em}\ra \blc{B^\M}\,(\gamma_0,\,x_0)\,(\gamma_1,\,x_1)\,(\gamma^M,\,x^M)\,(f_0\,x_0)\,(f_1\,x_1)}
\end{alignat*}
\endgroup

We interpret the universe as relation space, and function types as types
expressing pointwise relatedness of functions. This interpretation works the
same way for unrestricted (non-strictly positive) function types as well.

However, we would like to have underlying functions instead of relations in
homomorphisms. We take hint from the fact that for classical (simply-typed)
algebraic theories, a logical relation is equivalent to a homomorphism if and
only if the underlying relation is the graph of a function
\cite[pg. 5]{udayReynolds}. Thus we make the following change:
\begin{alignat*}{5}
  & \U^\M\,\hat{\gamma_0\,\gamma_1\,\gamma^M\,A_0\,A_1} && :\equiv \hat{A_0\ra A_1}
\end{alignat*}
This requires us to change $(\underline{a})^\M$ as well, since we need to
produce a type as result, but $a^M$ now yields a function. We can morally keep
the old definition, by viewing the result of $a^M$ as a functional relation, and
relating $t_0$ and $t_1$ by its graph:
\begin{alignat*}{5}
  & (\underline{a})^\M\,\hat{\gamma_0\,\gamma_1\,\gamma^M\,t_0\,\,t_1} && :\equiv \hat{
    \blc{a^\M}\,\gamma_0\,\gamma_1\,\gamma^M\,t_0 = t_1}
\end{alignat*}
At this point we have merely restricted relations to functions, and left the
rest of the interpretation unchanged. However, this is not strictly the desired
notion of homomorphism. Consider the $\blank^\M$ interpretation for natural
numbers:
\begin{alignat*}{5}
  & && (\boldsymbol{\cdot},Nat : \U,zero:\underline{Nat},suc:Nat\ra\underline{Nat})^\M
    \,\hat{(\tt,\,N_0,\,z_0,\,s_0)\,(\tt,\,N_1,\,z_1,\,s_1)} \\
    & \equiv\,\, && \hat{\top\times(N^M : N_0\ra N_1)}\\
    & && \hat{\hspace{1em}\times\,\,(z^M : N^M\,z_0 = z_1)}\\
    & && \hat{\hspace{1em}\times\,\,(s^M : (x_0 : N_0)(x_1 : N_1)(x^M : N^M\,x_0 = x_1)\ra N^M\,(s_0\,x_0)=s_1\,x_1)}
\end{alignat*}
In $\hat{s^M}$, there is a superfluous $\hat{x^M}$ equality proof. Fortunately,
in the translation of the inductive function space, we can just singleton
contract $\hat{x^M}$ away, yielding an equivalent, but stricter definition:
\begin{alignat*}{5}
  & ((x:a)\ra B)^\M\,\hat{\gamma_0\,\gamma_1\,\gamma^M\,f_0\,f_1} :\equiv \\
  & \hat{\hspace{2em}(x_0 : \blc{a^\A}\,\gamma_0)\ra \blc{B^\M}\,(\gamma_0,\,x_0)\,(\gamma_1,\,\blc{a^\M}\,\gamma_0\,\gamma_1\,\gamma^M\,x_0)\,(\gamma^M,\,\refl)\,
    (f_0\,x_0)\,(f_1\,(\blc{a^\M}\,\gamma_0\,\gamma_1\,\gamma^M\,x_0))}
\end{alignat*}
Now, the $\beta$-rule for successors is as expected:
\begin{alignat*}{5}
 & \hat{s^M : (x_0 : N_0)\ra N^M\,(s_0\,x_0)=s_1\,(N^M\,x_0)}
\end{alignat*}

Note that this singleton contraction is not possible for a general non-strictly
positive function space. We rely on the domain being small: $(\underline{a})^\M$
yields an equation, but for general $\hat{\Gamma;\,}\Delta\vdash A$ types, $A^\M$ only yields
an unknown relation.

\subsection{The full homomorphism interpretation} We list below the $\blank^\M$
interpretations for the syntax. For brevity, we mostly leave $\hat{\gamma_0}$
and $\hat{\gamma_1}$ implicit, notating only $\hat{\gamma^M}$ where necessary.
We also omit some subscript parameters from $\hat{\J}$ applications.

\begingroup
\allowdisplaybreaks
\begin{alignat*}{5}
  & \boldsymbol{\cdot}^\M\hat{\gamma_0\,\gamma_1} && :\equiv \hat{\top} \\
  & (\Delta,x:A)^\M\,\hat{\gamma_0\,\gamma_1} && :\equiv \hat{(\gamma^M : \blc{\Delta^\M}\,\gamma_0\,\gamma_1)\times \blc{A^\M}\,\gamma^M} \\
  & x^\M\,\hat{\gamma^M} && :\equiv x^{\text{th}}\text{ component in } \hat{\gamma^M} \\
  & \U^\M\,\hat{\gamma^M\,A_0\,A_1} && :\equiv \hat{A_0\ra A_1} \\
  & (\underline{a})^\M\,\hat{\gamma^M\,t_0\,\,t_1} && :\equiv \hat{
    \blc{a^\M}\,\gamma^M\,t_0 = t_1} \\
  & ((x:a)\ra B)^\M\,\hat{\gamma^M\,f_0\,f_1} && :\equiv \\
  & && \hat{\hspace{-8em}(x_0 : \blc{a^\A}\,\gamma_0)\ra \blc{B^\M}\,(\gamma_0,\,x_0)\,(\gamma_1,\,\blc{a^\M}\,\gamma^M\,x_0)\,(\gamma^M,\,\refl)\,
    (f_0\,x_0)\,(f_1\,(\blc{a^\M}\,\gamma^M\,x_0))}\\
  & (t\,u)^\M\,\hat{\gamma^M} && :\equiv  \hat{\J\,(\blc{t^\M}\,\gamma^M\,(\blc{u^\A}\,\gamma_0))\,(\blc{u^\M}\,\gamma^\M) }\\
  & ((\hat{x:A})\ra B)^\M\,\hat{\gamma^M\,f_0\,f_1} && :\equiv \hat{(x : A)\ra \blc{B^\M}\,\gamma^M\,(f_0\,x)\,(f_1\,x)} \\
  & (t\,\hat{u})^\M\,\hat{\gamma^M} && :\equiv t^\M\,\hat{\gamma^M\,u} \\
  & (t=_a u)^\M\,\hat{\gamma^M} && :\equiv
    \hat{\lambda\,e.\,(\blc{t^\M}\,\gamma^M\,^{-1})\sqcdot\ap\,(\blc{a^\M}\,\gamma^M)\,e\sqcdot\,\blc{u^\M}\,\gamma^M}\\
  & (\refl_t)^\M\,\hat{\gamma^M} && :\equiv \hat{\inv\,(\blc{t^\M}\,\gamma^M)}\\
  & (\J_{a\,t\,(x.z.p)}\,pr\,_u\,eq)^\M\,\hat{\gamma^M} && :\equiv\\
  & && \hspace{-10em}\hat{\J\,\bigg(\J\,\Big(\J\,\big(\J\,(\lambda\,p_1\,p^M\,pr_1\,pr^M.\, pr^M)\,(\blc{t^\M}\,\gamma^M)}  \\
  & && \hspace{-9em}\hat{
      (\mathsf{uncurry}\,\blc{p^\A}\,\gamma_1)\,(\mathsf{uncurry}\,\blc{p^\M}\,\gamma^M)\,
      (\blc{pr^\A}\,\gamma_1)\,(\blc{pr^\M}\,\gamma^M)\big)\,
        (\blc{eq^\A}\,\gamma_0)\Big)(\blc{u^\M}\,\gamma^M)\bigg)(\blc{eq^\M}\,\gamma^M)   }\\
  & (\J\beta_{a\,t\,(x.z.p)}\,pr)^\M\,\hat{\gamma^M} && :\equiv\\
  & && \hspace{-9em}\hat{
    \J\,\big(\J\,(\lambda\,p_1\,p^M.\,\refl)\,(\blc{t^\M}\,\gamma^M)\,
      (\mathsf{uncurry}\,\blc{p^\A}\,\gamma_1)\,
      (\mathsf{uncurry}\,\blc{p^\M}\,\gamma^M)\big)
      (\blc{pr^\M}\,\gamma^M)
    }\\
  & ((\hat{x}\in \hat{A})\ra b)^\M\,\hat{\gamma^M} && :\equiv
       \hat{\lambda f\,x.\,\,\blc{b^\M}\,\gamma^M\,(f\,x)} \\
  & (t\,\hat{u})^\M\,\hat{\gamma^M} && :\equiv
       \hat{\ap\,(\lambda f.\,f\,u)\,(\blc{t^\M}\,\gamma^M)}
\end{alignat*}
\endgroup


%% --------------------------------------------------------------------------------

\section{Displayed Algebras}
\label{sec:displayed}

The $\blank^\D$ translation computes displayed algebras for a signature, which
can be viewed as bundles of induction motives and methods. $\blank^\D$ is
essentially an unary logical predicate translation over the $\blank^\A$
model. It is related to the logical predicate translation of Bernardy et
al.\ \cite{bernardy12parametricity}, but our implementation differs by
interpreting contexts as $\Sigma$-types instead of extended contexts.

For each
context $\Delta$, $\Delta^\D$ is a predicate over the standard interpretation
$\Delta^\A$. For a type $\Delta\vdash A$, $A^\D$ is a predicate over $A^\A$,
which also depends on $\hat{\gamma}\in\Delta^\A$ and a witness of
$\Delta^\D\,\hat{\gamma}$. All of these may refer to a target theory context
$\hat{\Gamma}$.
\[
\infer{\hat{\Gamma}\vdashh\Delta^\D \in \Delta^\A\rah \Type_{\hat{i+1}}}{\hat{\Gamma}\vdash\Delta}
\hspace{2em}
\infer{
  \hat{\Gamma}\vdashh A^\D \in \hat{(}\hat{\gamma}\in\Delta^\A\hat{)}\rah \Delta^\D\,\hat{\gamma}\rah  A^\A\,\hat{\gamma}\rah \Type_{\hat{i+1}}}
      {\hat{\Gamma}\semicol\Delta\vdash A}
\]
For a term $t$, $t^\D$ witnesses that the predicate corresponding to its type
holds for $t^\A$; again this can be viewed as a fundamental theorem for the
predicate interpretation.

\[
\infer{\hat{\Gamma}\vdashh t^\D \in \hat{(}\hat{\gamma}\in\Delta^\A\hat{)}\hat{(}\hat{\gamma^D}\in\Delta^\D\,\hat{\gamma}\hat{)}\rah  A^\D\,\hat{\gamma}\,\hat{\gamma^D}\,\hat{(}t^\A\,\hat{\gamma}\hat{)}}{\hat{\Gamma}\semicol\Delta\vdash t : A}
\]
The implementation of $\blank^\D$ is given below. We leave
$\hat{\gamma}$-s mostly implicit, marking only $\hat{\gamma^D}$ witnesses.
\begingroup
%% \allowdisplaybreaks
\begin{alignat*}{5}
  & \boldsymbol{\cdot}^D\,\hat{\gamma} && :\equiv \hat{\top} \\
  & (\Delta,\,x:A)^D\,(\hat{\gamma}\commah\,\hat{t}) && :\equiv \hat{(}\hat{\gamma^D}\in\Delta^D\,\hat{\gamma}\hat{)}\timesh A^D\,\hat{\gamma^D}\,\hat{t} \\
  & x^D\,\hat{\gamma^D} && :\equiv x^{\text{th}}\text{ component in } \hat{\gamma^D} \\
  & \U^D\,\hat{\gamma^D}\,\hat{A} && :\equiv \hat{A} \rah  \Type_{\hat{i}} \\
  & (\underline{a})^D\,\hat{\gamma^D}\,\hat{t} && :\equiv a^\D\,\hat{\gamma^D}\,\hat{t} \\
  & ((x:a)\ra B)^D\,\hat{\gamma^D}\,\hat{f} && :\equiv \hat{(}\hat{x}\in a^\A\,\hat{\gamma}\hat{)}\hat{(}\hat{x^D}\in a^\D\,\hat{\gamma^D}\,\hat{x}\hat{)} \rah  B^\D\,\hat{(}\hat{\gamma}\commah\hat{x}\hat{)}\,\hat{(}\hat{\gamma^D}\commah\hat{x^D}\hat{)}\,\hat{(}\hat{f}\,\hat{x}\hat{)} \\
  & (t\,u)^D\,\hat{\gamma^D} && :\equiv \hat{(}t^\D\,\hat{\gamma^D}\hat{)}\,\hat{(} u^\A\,\hat{\gamma}\hat{)}\,\hat{(}u^\D\,\hat{\gamma^D}\hat{)} \\
  & ((\hat{x}\in \hat{A})\ra B)^D\,\hat{\gamma^D}\,\hat{f} && :\equiv \hat{(}\hat{x}\in \hat{A}\hat{)}\rah  B^\D\,\hat{\gamma^D}\,\hat{(}\hat{f}\,\hat{x}\hat{)} \\
  & (t\,\hat{u})^D\,\hat{\gamma^D} && :\equiv t^\D\,\hat{\gamma^D}\,\hat{u} \\
  & (t=_a u)^D\,\hat{\gamma^D}\,\hat{e} && :\equiv \TR_{\hat{(}a^\D\,\hat{\gamma^D}\hat{)}}\,\hat{e}\,\hat{(}t^\D\,\hat{\gamma^D}\hat{)} \eqh u^\D\hat{\gamma^D} \\
  & (\refl_t)^D\,\hat{\gamma^D} && :\equiv \hat{\refl}_{\hat{(}t^\D\,\hat{\gamma^D}\hat{)}} \\
  & (\J_{a\,t\,(x.z.p)}\,pr\,_u\,eq)^D\,\hat{\gamma^D} && :\equiv \hat{\J}\,\hat{\big(}\hat{\J}\,\hat{(}pr^\D\,\hat{\gamma^D}\hat{)}\,\hat{(}eq^\A\,\hat{\gamma}\hat{)}\hat{\big)}\,\hat{(}eq^\D\,\hat{\gamma^D}\hat{)} \\
  & (\J\beta_{a\,t\,(x.z.p)}\,pr)^D\,\hat{\gamma^D} && :\equiv \hat{\refl} \\
  & ((\hat{x}\in \hat{A})\ra b)^D\,\hat{\gamma^D}\,\hat{f} && :\equiv \hat{(}\hat{x}\in \hat{A}\hat{)}\rah  b^D\,\hat{\gamma^D}\,\hat{(}\hat{f}\,\hat{x}\hat{)} \\
  & (t\,\hat{u})^D\,\hat{\gamma^D} && :\equiv t^\D\,\hat{\gamma^D}\,\hat{u}
\end{alignat*}
\endgroup
The predicate for a context is given by iterating $\blank^\D$ for its
constituent types. For a variable, the corresponding witness is looked up from
$\hat{\gamma^D}$.

The translation of the universe, given an element of
$\hat{A}\in\U^\A\,\hat{\gamma}$ (with
$\U^\A\,\hat{\gamma}\equiv\Type_{\hat{0}}$) returns the predicate space over
$\hat{A}$. For $\underline{a}$ types, we just return the translation of $a$.

The predicate for a function type for inductive parameters expresses
preservation of predicates. Witnesses of application are given by recursive
application of $\blank^\D$. The definitions for the other (non-inductive)
function spaces are similar, except there is no predicate for the domain types,
and thus no witnesses are required.

The predicate for the equality type $t=_a u$, for each $\hat{e}\in(t=_a
u)^\A\,\hat{\gamma}$, i.e.\ $\hat{e}\in t^\A\,\hat{\gamma}\eqh
u^\A\,\hat{\gamma}$, says that $t^\D$ and $u^\D$ are equal. As these have
different types, we have to transport over the original equality
$\hat{e}$. Hence, induction methods for path constructors will be \emph{paths
  over paths} in the sense of homotopy type theory.

$\refl$ is interpreted with just reflexivity in the target syntax. The
interpretation of $\J$ is given by a double $\hat{\J}$ application, borrowing
the definition from Lasson \cite{lasson}. Here, we use a shortened $\hat{\J}$
notation; see the formalization (Section \ref{sec:formalization}) for details.

Again, let us consider the circle example:
\begin{alignat*}{5}
  & && (\boldsymbol{\cdot},\,S^1 : \U,\,b:\underline{S^1},\,loop: \underline{b=b})^\D\,\,\hat{(}\hat{\tt,\,S^1,\,b,\,loop}\hat{)}\\
  & \equiv \,\, && \hat{\top}\timesh\hat{(}\hat{S^{1D}}\in \hat{S^1}\rah\Type_{\hat{i}}\hat{)}\timesh\hat{(}\hat{b^D}\in \hat{S^{1D}\,b}\hat{)}\timesh\hat{(}\hat{loop^D\in \TR_{\,S^{1D}}\,loop\,b^D = b^D}\hat{)}
\end{alignat*}
The inputs of $\blank^\D$ here are the signature for the circle (the context in
black) and an $\hat{S^{1}}$-algebra consisting of three non-$\top$ components.
It returns a family over the type $\hat{S^1}$, an element of this family
$\hat{b^D}$ at index $\hat{b}$, and and an equality between $\hat{b^D}$ and
$\hat{b^D}$ which lies over $\hat{loop}$. This is the same as the usual
induction motives and methods for the circle, e.g.\ as described in \cite{HoTTbook}.

%% --------------------------------------------------------------------------------

\section{Displayed Algebra Sections}
\label{sec:sections}

The operation $\blank^\S$ yields displayed algebra sections. It is a generalized
binary logical relation translation where the type of the second parameter of
the relation may depend on the first parameter. Displayed algebra sections can
be viewed as dependent homomorphisms: while homomorphisms are
structure-preserving families of functions, sections are structure-preserving
families of dependent functions.

Contexts are interpreted as dependent binary relations between algebras and
displayed algebras. The universe level $i$ was previously chosen for the
$\blank^\M$ and $\blank^\D$ translations.
\[
\infer{\hat{\Gamma}\semicol\Delta^\S \in \hat{(}\hat{\gamma}\in\Delta^\A\hat{)}\rah \Delta^\D\,\hat{\gamma}\rah \Type_{\hat{i}}}{\hat{\Gamma}\vdash\Delta}
\]
Types are interpreted as dependent binary relations which additionally depend on
$\hat{\gamma}$, $\hat{\gamma^D}$, $\hat{\gamma^S}$ interpretations of the
context.
\[
\infer{\hat{\Gamma}\vdashh A^\S \in \hat{(}\hat{\gamma}\in\Delta^\A\hat{)}\hat{(}\hat{\gamma^D}\in\Delta^\D\,\hat{\gamma}\hat{)}\hat{(}\hat{\gamma^S}\in\Delta^\S\,\hat{\gamma}\,\hat{\gamma^D}\hat{)}\hat{(}\hat{x}\in A^\A\,\hat{\gamma}\hat{)}\rah  A^\D\,\hat{\gamma}\,\hat{\gamma^D}\,\hat{x}\rah \Type_{\hat{i}}}{\hat{\Gamma}\semicol\Delta\vdash A}
\]
For a term $t$, $t^\S$ witnesses that the relation corresponding to
its type holds for $t^\A$ and $t^\D$.
\[
\infer{\hat{\Gamma}\vdashh t^\S \in \hat{(}\hat{\gamma}\in\Delta^\A\hat{)}\hat{(}\hat{\gamma^D}\in\Delta^\D\,\hat{\gamma}\hat{)}\hat{(}\hat{\gamma^S}\in\Delta^\S\,\hat{\gamma}\,\hat{\gamma^D}\hat{)}\rah  A^\S\,\hat{\gamma}\,\hat{\gamma^D}\,\hat{\gamma^S}\,\hat{(}t^\A\,\hat{\gamma}\hat{)}\,\hat{(}t^\D\,\hat{\gamma}\,\hat{\gamma^D}\hat{)}}{\hat{\Gamma}\semicol\Delta \vdash t : A}
\]
Here, we mostly notate $\hat{\gamma^S}$ parameters and applications, making
$\hat{\gamma^D}$-s implicit in addition to $\hat{\gamma}$-s. The implementation
is the following.
\begingroup
%% \allowdisplaybreaks
\begin{alignat*}{5}
  & \boldsymbol{\cdot}^\S\,\hat{\gamma}\,\hat{\gamma^D} && :\equiv \hat{\top} \\
  & (\Delta,\,x:A)^\S\,(\hat{\gamma},\hat{t})\,(\hat{\gamma^D},\hat{t^D}) && :\equiv \hat{(}\hat{\gamma^S}\in\Delta^\S\hat{\gamma^2}\hat{)}\timesh A^\S\,\hat{\gamma^S}\,\hat{t}\,\hat{t^D} \\
  & x^\S\,\hat{\gamma^S} && :\equiv x^{\text{th}}\text{ component in } \hat{\gamma^S} \\
  & \U^\S\,\hat{\gamma^S}\,\hat{A}\,\hat{A^D} && :\equiv \hat{(}\hat{x}\in \hat{A}\hat{)}\rah  \hat{A^D}\,\hat{x} \\
  & (\underline{a})^\S\,\hat{\gamma^S}\,\hat{t}\,\hat{t^D} && :\equiv a^\S\,\hat{\gamma^S}\,\hat{t} \eqh \hat{t^D} \\
  & ((x:a)\ra B)^\S\,\hat{\gamma^S}\,\hat{f}\,\hat{f^D} && :\equiv \hat{(}\hat{x}\in a^\A\,\hat{\gamma}\hat{)}\rah  B^\S\,\hat{(}\hat{\gamma,x}\hat{)}\,\hat{(}\hat{\gamma^D,}\,a^\S\,\hat{\gamma^S}\,\hat{x}\hat{)}\,\hat{(}\hat{\gamma^S,}\,\hat{\refl}\hat{)} \\
  & && \hspace{8.4em} \hat{(}\hat{f}\,\hat{x}\hat{)}\,\hat{\big(}\hat{f^D}\,\hat{x}\,\hat{(}a^\S\,\hat{\gamma^S}\,\hat{x}\hat{)}\hat{\big)} \\
  & (t\,u)^\S\,\hat{\gamma^S} && :\equiv \hat{\J}\,\hat{(}t^\S\,\hat{\gamma^S}\,\hat{(} u^\A\,\hat{\gamma}\hat{)}\hat{)}\,\hat{(}u^\S\,\hat{\gamma^S}\hat{)} \\
  & ((\hat{x}\in \hat{A})\ra B)^\S\,\hat{\gamma^S}\,\hat{f}\,\hat{f^D} && :\equiv \hat{(}\hat{x}\in \hat{A}\hat{)}\rah B^\S\,\hat{\gamma^S}\,\hat{(}\hat{f}\,\hat{x}\hat{)}\,\hat{(}\hat{f^D}\,\hat{x}\hat{)} \\
  & (t\,\hat{u})^\S\,\hat{\gamma^S} && :\equiv t^\S\,\hat{\gamma^S}\,\hat{u} \\
  & (t=_a u)^\S\,\hat{\gamma^S}\,\hat{e} && :\equiv \TR\,\hat{(}t^\S\,\hat{\gamma^S}\hat{)}\hat{\big(}\TR\,\hat{(}u^\S\,\hat{\gamma^S}\hat{)}\,\hat{(}\apd\,\hat{(}a^\S\,\hat{\gamma^S}\hat{)}\,\hat{e}\hat{)}\hat{\big)} \\
  & (\refl_t)^\S\,\hat{\gamma^S} && :\equiv \hat{\J}\,\hat{\refl}\,\hat{(}t^\S\,\hat{\gamma^S}\hat{)} \\
  & (\J_{a\,t\,(x.z.p)}\,pr\,_u\,eq)^\S\,\hat{\gamma^S} && :\equiv \\
  & && \hspace{-10em}\hat{\J}\,\hat{\bigg(}\hat{\J}\,\hat{\Big(}\hat{\J}\,\hat{\big(}\hat{\J}\,\hat{(}\hat{\lambda}\,\hat{p^D}\,\hat{p^S}\,\hat{pr^D}\,\hat{pr^S}.\,\hat{pr^S}\hat{)}\,\hat{(}t^\S\,\hat{\gamma^S}\hat{)}\,\\
  & && \hspace{-9em}\hat{(}\hat{\mathsf{uncurry}}\,p^\D\,\hat{\gamma^2}\hat{)}\,\hat{(}\hat{\mathsf{uncurry}}\,p^\S\,\hat{\gamma^S}\hat{)}\,\hat{(}pr^\D\,\hat{\gamma^2}\hat{)}\,\hat{(}pr^\S\,\hat{\gamma^S}\hat{)}\hat{\big)}\,(eq^\A\,\hat{\gamma})\hat{\Big)}\,(u^\S\,\hat{\gamma^S})\hat{\bigg)}\,\hat{(}eq^\S\,\hat{\gamma^S}\hat{)} \\
  & (\J\beta_{a\,t\,(x.z.p)}\,pr)^\S\,\hat{\gamma^S} && :\equiv \\
  & && \hspace{-10em}\hat{\J}\,\hat{\big(}\hat{\J}\,\hat{(}\hat{\lambda}\,\hat{p^D}\,\hat{p^S}\hat{.}\,\hat{\refl}\hat{)}\,\hat{(}t^\S\,\hat{\gamma^S}\hat{)}\,\hat{(}\hat{\mathsf{uncurry}}\,p^\D\,\hat{\gamma^2}\hat{)}\,\hat{(}\hat{\mathsf{uncurry}}\,p^\S\,\hat{\gamma^S}\hat{)}\hat{\big)}\,\hat{(}pr^\S\,\hat{\gamma^S}\hat{)}\\
  & ((\hat{x}\in \hat{A})\ra b)^\S\,\hat{\gamma^S\,f\,t} && :\equiv b^\S\,\hat{\gamma^S}\,\hat{(}\hat{f}\,\hat{t}\hat{)} \\
  & (t\,\hat{u})^\S\,\hat{\gamma^S} && :\equiv \ap\,\hat{(}\hat{\lambda} \hat{f.}\hat{f}\,\hat{u}\hat{)}\,\hat{(}t^\S\,\hat{\gamma^S}\hat{)}
\end{alignat*}
\endgroup

The $\U^\S$ and $(\underline{a})^\S$ definitions are the key points of
the $\blank^\S$ operation. The definitions for the other $\blank^\S$
cases are largely determined by these.

The $\U^\S$ rule yields the type of the eliminator for a type
formation rule. In the natural numbers example above, the non-indexed
$Nat : \U$ sort is interpreted as $\hat{\hat{n^S} \in (\hat{x}\in
\hat{n})\rah \hat{n^D}\,\hat{x}}$. For indexed sorts, the indices are
first processed by the $\blank^\S$ cases for inductive and non-inductive
parameters, until the ultimate $\U$ return type is reached. Hence, the
eliminator for a sort is always a function.

Analogously, the $\blank^\S$ result type for a point or path constructor is
always a $\beta$-rule, i.e.\ a function type ending in an equality. To
see why, consider the $(\underline{a})^\S$ definition. It expresses
that applications of $a^\S$ eliminators must be equal to the
corresponding $\hat{t^D}$ induction methods. Hence, for path and point
constructor types, $\blank^\S$ works by first processing all inductive and
non-inductive indices, then finally returning an equality type.

Let us also consider the $((x:a)\ra B)^\S$ case for inductive
parameters. Here, we make crucial use of the fact that the domain type
$a$ is small. This provides us $a^\S\,\hat{\gamma^3\,x}$, which we use
to witness the $a^\D\,\hat{\gamma^2}\,\hat{x}$ hypothesis for
$B^\S$. Without the size restriction on inductive parameters (which
enforces strict positivity), the $\blank^\S$ operation would not be
possible at all, because $a^\S$ for a large $a$ type would be merely
an opaque relation instead of an eliminator function.

Here, we only provide abbreviated definitions for the $t\,u$, $t=_a
u$, $\refl$, $\J$ and $\J\beta$ cases. In the $\J$ case, we write
$\hat{\mathsf{uncurry}}\,p^\D$ for
$\hat{\lambda\,\gamma\,\gamma^D\,x\,x^D\,z\,z^D.}\,p^\D\,(\hat{\gamma,x,z})\,(\hat{\gamma^D,x^D,z^D})$
and analogously elsewhere. The full definitions can be found in the
Agda formalization. The definitions are highly constrained by the
required types, and not particularly difficult to implement with the
help of a proof assistant; they all involve doing successive path
induction on all equalities available from induction hypotheses, with
appropriately generalized induction motives.

The full $(\J_{a\,t\,(x.z.p)}\,pr\,_u\,eq)^\S$ definition is quite
large, and, for instance, yields a very large $\beta$-rule for the
higher inductive torus definition (the reader can confirm this using
the Haskell implementation). Nevertheless, an implementation focused
on practicality may provide smaller specialized $\blank^\S$ definitions for
commonly used equality operations such as composition or inverses.

The circle example is a bit more interesting here:
\begin{alignat*}{5}
  & && (\boldsymbol{\cdot},\,S^1 : \U,\,b:\underline{S^1},\,loop: \underline{b=b})^\S\,\,\hat{(}\hat{\tt,\,S^1,\,b,\,loop}\hat{)}\,\hat{(}\hat{\tt,\,S^{1M},\,b^D,\,loop^D}\hat{)} \\
  & \equiv \,\, && \hat{\top}\timesh\hat{(}\hat{S^{1E}}\in \hat{(}\hat{x}\in\hat{S^1}\hat{)}\hat{\,\ra\,}\hat{S^{1M}\,x}\hat{)}\timesh\hat{(}\hat{b^S}\in \hat{S^{1E}\,\,b = b^D}\hat{)}\\
  & && \hspace{0.75em}\timesh\hat{(}\hat{loop^S\,\,\in\,\,} \TR\,_{\hat{(}\hat{\lambda x. \TR\,_{S^{1M}}\,loop\,x\,=\,b^D}\hat{)}}\,\hat{b^S}\,\hat{(}\TR\,_{\hat{(}\hat{\lambda} \hat{x}. \TR\,_{\hat{S^{1M}}}\,\hat{loop}\,\hat{(}\hat{S^{1E}\,b}\hat{)}\,\eqh\,\hat{x}\hat{)}}\,\hat{b^S}\,\hat{(}\apd\,\hat{S^{1E}\,loop}\hat{)}\hat{)}\,\\
  & && \hspace{5.5em} \hat{=\,loop^D}\hat{)}
\end{alignat*}
In homotopy type theory, the $\beta$-rule for $loop$ is usually just
$\apd\,\hat{S^{1E}\,loop}\,\hat{\,=\,loop^D}$, but here all
$\beta$-rules are propositional, so we need to transport with
$\hat{b^S}$ to make the equation well-typed. When computing the type
of $\hat{loop^S}$, we start with $(\underline{b
  =b})^S\,\,\hat{\gamma^3}\,\,\hat{loop}\,\,\hat{loop^D}$. Next, this
evaluates to $(b=b)^\S\,\hat{\gamma^3}\,\hat{loop}\eqh\hat{loop^D}$,
and then we unfold the left hand side to get the doubly-transported
expression in the result.

In Appendix \ref{sec:app}, we show how the elimination principle is
computed for the two-dimensional sphere.

For another example for the translations, we consider indexed W-types
which can describe a large class of inductive definitions
\cite{morris09indexed}. Suppose we are in the external context $\hat{I}
\in \Type_{\hat{0}}\commah\hat{S} \in \Type_{\hat{0}}\commah\hat{P} \in \hat{S} \rah
\Type_{\hat{0}}\commah\hat{out} \in \hat{S} \rah \hat{I}\commah\hat{in} \in
\hat{(}\hat{s} \in \hat{S}\hat{)}\rah \hat{P}\,\hat{s}\rah \hat{I}$. Then, the
code for the corresponding indexed W-type is the following:
\[
W :\equiv (\boldsymbol{\cdot},\,\,\,w:(\hat{i} \in \hat{I})\ra\U,\,\,\,sup: (\hat{s} \in \hat{S})\ra((\hat{p} \in \hat{P\,s})\ra w\,(\hat{in\,s\,p}))\ra \underline{w\,(\hat{out\,s})})
\]
We pick a universe level $j$ for elimination. The interpretations of $W$ are the following, omitting leading $\hat{\top}$ components:
\begin{alignat*}{5}
  & \rlap{$W^\A \equiv \hat{(}\hat{w}\in \hat{I}\rah\Type_{\hat{0}}\hat{)}\timesh\hat{(}\hat{(}\hat{s}\in \hat{S}\hat{)}\rah\hat{(}\hat{(}\hat{p}\in \hat{P\,s}\hat{)}\rah \hat{w}\,\hat{(}\hat{in\,s\,p}\hat{)}\hat{)}\rah \hat{w}\,\hat{(}\hat{out\,s}\hat{)}\hat{)}$}\\
  & W^\D\,\hat{(}\hat{w, sup}\hat{)} && \equiv\, && \hat{(}\hat{w^D} \in \hat{(}\hat{i}\in \hat{I}\hat{)}\rah \hat{w\,i}\rah \Type_{\hat{j}}\hat{)}\\
  & && \hspace{0.23em}\timesh && \hat{\big(}\hat{(}\hat{s\in S}\hat{)}\hat{(}\hat{f}\in \hat{(}\hat{p\in P\,s}\hat{)}\rah \hat{w}\,\hat{(}\hat{in\,s\,p}\hat{)}\hat{)}\\
  & && && \rah \hat{(}\hat{(}\hat{p\in P\,s}\hat{)}\rah \hat{w^D}\,\hat{(}\hat{in\,s\,p}\hat{)}\,\hat{(}\hat{f\,p}\hat{)}\hat{)}\rah \hat{w^D}\,\hat{(}\hat{out\,s}\hat{)}\,\hat{(}\hat{sup\,s\,f}\hat{)}\hat{\big)} \\
  & \rlap{$ W^\S\,\hat{(}\hat{w, sup}\hat{)}\,\hat{(}\hat{w^D,sup^D}\hat{)} \equiv $} \\
  & && && \hat{(}\hat{w^S} \in \hat{(}\hat{i \in I}\hat{)}\hat{(}\hat{x \in w\,i}\hat{)}\rah \hat{w^D\,i\,x}\hat{)}\\
  & && \hspace{0.23em}\timesh && \hat{\big(}\hat{(}\hat{s\in S}\hat{)}\hat{(}\hat{f}\in \hat{(}\hat{p\in P\,s}\hat{)}\rah \hat{w}\,\hat{(}\hat{in\,s\,p}\hat{)}\hat{)}\\
  & && && \rah \hat{w^S}\,\hat{(}\hat{out\,s}\hat{)}\,\hat{(}\hat{sup\,\,s\,f}\hat{)} \eqh \hat{sup^D\,s\,f}\,\hat{(}\hat{\lambda} \hat{p.}\, \hat{w^S}\,\hat{(}\hat{in\,s\,p}\hat{)}\,\hat{(}\hat{f\,p}\hat{)}\hat{)}\hat{\big)}
\end{alignat*}

%=====================================================================

\section{On Extension to Categorical Semantics}
\label{sec:categorical}

TODO

%% \section{Existence of HIITs}
%% \label{sec:adding}

%% The target type theory supports HIITs if whenever we can derive
%% $\hat{\Gamma}\vdash\Delta$ in the source theory, the following rules are
%% admissible.
%% \[
%% \infer{\hat{\Gamma}\vdashh\hat{\con}_\Delta\in \Delta^\C}{\vspace{1em}}
%% \hspace{5em}
%% \infer{\hat{\Gamma}\vdashh\hat{\elim}_\Delta\,\hat{m}\in\Delta^\E\,\hat{\con}_\Delta\,\hat{m}}{\hat{\Gamma}\vdashh \hat{m}\in \Delta^\M\,\hat{\con}_\Delta}
%% \]
%% We can add HIITs to the target theory by extending it with the theory
%% of codes (making the target and the source theory the same) and adding
%% the above rules with the additional assumption of
%% $\hat{\Gamma}\vdash\Delta$. However, this only adds HIITs with weak
%% computation rules. To make the computation rules definitional, we
%% would probably need a two-level target type theory with an equality
%% having an equality reflection rule as in Voevodsky's homotopy type
%% system \cite{hts} or Andromeda \cite{andromeda}.

%=====================================================================

\section{Formalization and Implementation}
\label{sec:formalization}

There are three additional development artifacts to the current work:
a Haskell implementation, a shallow Agda formalization and a deep Agda
formalization. All three are available from the homepage of the first
author.

The Haskell implementation takes as input a file which contains a
representation of a $\hat{\Gamma}\vdash\Delta$ specification of a
HIIT. Then, it checks the input with respect to the rules in Figure
\ref{sigrules}, and outputs an Agda-checkable file which contains the
results of the $\blank^\C$, $\blank^\M$ and $\blank^\E$
translations. It comes with examples, including the ones in this
paper, indexed W-types \cite{morris09indexed}, the dense completion
\cite[Appendix A.1.3]{forsberg-phd} and several HITs from
\cite{HoTTbook} including the definition of Cauchy reals. It can be
checked that our implementation computes the expected elimination
principles in these cases.

The shallow Agda formalization embeds both the source and target theories
shallowly into Agda: it represents types as Agda types, functions as
Agda functions, and so on. We also leave the $\blank^\C$ operation
implicit. We state each case of the $\blank^\M$ and $\blank^\E$
translations as Agda functions from all induction hypotheses to the
result type of the translation, which lets us ``typecheck'' the
translation. We have found that this style of formalization is
conveniently light, but remains detailed enough to be useful. We also
generated some of the code of the Haskell implementation from this
formalization.

The deep Agda formalization still uses a shallow embedding of the
target type theory, but it uses a deep embedding of the source theory,
in the style of \cite{ttintt}. In the formalization we merge the three
translations into a single model construction. This allows us to prove
strict preservation of definitional equalities in the substitution
calculus of the source theory, in contrast to the shallow
formalization, where we cannot reason about definitional equalities of
Agda terms. Due to technical challenges, this formalization uses
transport instead of $\J$ in the source theory, but this still covers
a rather large class of HIIT definitions.

%=====================================================================

\section{Conclusions and further work}
\label{sec:summary}

Higher inductive-inductive types are useful in defining the well-typed
syntax of type theory in an abstract way \cite{ttintt}. From a
universal algebra point of view, they provide initial algebras for
multi-sorted algebraic theories where the sorts can depend on each
other. From the perspective of homotopy type theory, they provide
synthetic versions of homotopy-theoretic constructions such as higher
dimensional spheres or cell complexes. So far, no general scheme of
HIITs have been proposed. To quote Lumsdaine and Shulman
\cite{lumsdaineShulman}:
\begin{quotation}
``The constructors of an ordinary inductive type are unrelated to each
other.  But in a higher inductive type each constructor must be able
to refer to the previous ones; specifically, the source and target of
a path-constructor generally involve the previous
point-constructors. No syntactic scheme has yet been proposed for this
that covers all cases of interest while remaining meaningful and
consistent.''
\end{quotation}
In this paper we proposed such a syntactic scheme which also includes
inductive-inductive types. We tackled the problem of complex
dependencies on previous type formation rules and constructors by a
well-known method of describing intricate dependencies: the syntax of
type theory itself. We had to limit the type formers to only allow
strictly positive definitions, but these restrictions are the only
things that a type theorist has to learn to understand our codes. Our
encoding is also \emph{direct} in the sense that the types of
constructors and eliminators are exactly as required and not merely up
to isomorphisms.

In this paper we only \emph{specified} HIITs and characterized their
induction principles. Proving their \emph{existence} is left as
further work. This would likely involve reducing HIITs to basic
building blocks such as W-types and quotient types.

The theory of codes was defined as part of the syntax of another type
theory, the target theory. An alternative way would be to define
the theory of codes internally to a type theoretic metatheory in the
style of \cite{ttintt}. However, as described in \cite[Section
  6]{ttintt}, there would be a coherence problem: for the internal
syntax to be useful, we need to truncate it to be a set (as the
$\mathsf{trunc}$ constructor did for $\Int$ in the introduction). As
the eliminator needs to respect the equality given by
$\mathsf{trunc}$, we would only be able to eliminate from the internal
type theory into a set. This would preclude the definition of even the
$\blank^\C$ operation, which corresponds to the standard model. A
possible solution to this problem would be to add all the higher
coherence laws to the syntax (e.g.\ the pentagon law for the
composition of substitutions) and then prove that the syntax is a
set. For this however, we would probably need a two-level metatheory
as in \cite{semisegal}.

When working in a metatheory with uniqueness of identity proofs (which
implies that all HIITs are in essence QIITs), the theory of codes
admits a category model where the interpretation of a context is the
category of algebras corresponding to the context. In the future, we
would like to prove that these categories have initial algebras given
by terms in the theory of codes.

\bibliographystyle{plain}
\bibliography{b}

\appendix
\section{Elimination principle computed for the two-dimensional sphere}
\label{sec:app}

The two-dimensional sphere is given by the following context in the
theory of codes.
\[
\Gamma :\equiv \Big(\boldsymbol{\cdot},\,\,\,S^2:\U,\,\,\,b:\underline{S^2},\,\,\,surf:\underline{\refl_{b} =_{(b=_{S^2} b)} \refl_{b}}\Big)
\]
The sphere-algebras are computed as follows.
\begin{alignat*}{5}
  & && \Gamma^\C \equiv \hat{\top}\timesh\hat{(}\hat{S^2}\in\Type_{\hat{0}}\hat{)}\timesh\hat{(}\hat{b}\in \hat{S^2}\hat{)}\timesh\hat{(}\hat{surf\in \hat{\refl_{\hat{b}}}=_{\hat{(}\hat{b}=_{\hat{S^2}}\hat{b}\hat{)}}\hat{\refl_{\hat{b}}}}\hat{)}
\end{alignat*}
Given a sphere-algebra and fixing a universe level $i$, the motives
and methods are computed as follows.
\begin{alignat*}{5}
  & && \Gamma^\M\,\,\hat{(}\hat{\tt,\,S^2,\,b,\,surf}\hat{)}\\
  & \equiv \,\, && \hat{\top}\timesh\hat{(}\hat{S^{2M}}\in \hat{S^2}\rah\Type_i\hat{)} \\
  & && \hspace{0.75em} \timesh\hat{(}\hat{b^M}\in \hat{S^{2M}\,b}\hat{)} \\
  & && \hspace{0.75em} \timesh\hat{(}\hat{surf^M\in \TR_{\hat{(}\TR_{S^{2M}}\,\blank\,b^M=b^M\hat{)}}\,surf\,\refl_{b^M} = \refl_{b^M}}\hat{)}
\end{alignat*}
Given a sphere-algebra and a displayed algebra over it, we get the type of sections:
\begin{alignat*}{5}
  & && \Gamma^\E\,\,\hat{(}\hat{\tt,\,S^2,\,b,\,surf}\hat{)}\,\hat{(}\hat{\tt,\,S^{2M},\,b^M,\,surf^M}\hat{)} \\
  & \equiv \,\, && \hat{\top}\timesh\hat{(}\hat{S^{2E}}\in \hat{(}\hat{x}\in\hat{S^2}\hat{)}\hat{\,\ra\,}\hat{S^{2M}\,x}\hat{)} \\
  & && \hspace{0.75em} \timesh\hat{(}\hat{b^E}\in \hat{S^{2E}\,\,b = b^M}\hat{)}\\
  & && \hspace{0.75em} \timesh\hat{\bigg(}\hat{surf^E\,\,\in\,\,} \TR\,\hat{\Big(}\hat{\J\,\refl\,b^E}\hat{\Big)}\,\hat{\Big(}\TR\,\hat{\big(}\hat{\J\,\refl\,b^E}\hat{\big)}\,\hat{\big(}\hat{\apd}\,\hat{(}\hat{\lambda} \hat{x}.\TR\,\hat{b^E}\,\hat{(}\TR\,\hat{b^E}\,\hat{(}\hat{\apd}\,\hat{S^{2E}}\,\hat{x}\hat{)}\hat{)}\hat{)}\,\hat{surf}\hat{\big)}\hat{\Big)} \\
  & && \hspace{5.5em} \hat{=} \,\hat{surf^M}\hat{\bigg)}
\end{alignat*}
Note that if $\hat{b^E}$ is a definitional equality (that is, we have
$\hat{S^{2E}\,\,b} \equiv \hat{b^M}$), the occurrences of $\hat{b^E}$
in the type of $\hat{surf^E}$ can be replaced by $\hat{\refl}$. In
this case the type of $\hat{surf^E}$ becomes the expected
$\hat{\apd}\,\hat{(}\hat{\apd}\,\hat{S^{2E}}\hat{)}\,\hat{surf}\,\hat{=}\,\hat{surf^M}$.

%=====================================================================


\end{document}
